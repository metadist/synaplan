<?php
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: model_config.proto

namespace Inference;

use Google\Protobuf\Internal\GPBType;
use Google\Protobuf\Internal\GPBUtil;
use Google\Protobuf\RepeatedField;

/**
 *\@\@
 *\@\@.. cpp:var:: message ModelConfig
 *\@\@
 *\@\@   A model configuration.
 *\@\@
 *
 * Generated from protobuf message <code>inference.ModelConfig</code>
 */
class ModelConfig extends \Google\Protobuf\Internal\Message
{
    /**
     *\@\@  .. cpp:var:: string name
     *\@\@
     *\@\@     The name of the model.
     *\@\@
     *
     * Generated from protobuf field <code>string name = 1;</code>
     */
    protected $name = '';
    /**
     *\@\@  .. cpp:var:: string platform
     *\@\@
     *\@\@     Additional backend-specific configuration for the model.
     *\@\@     Please refer to the backend documentation on whether this field
     *\@\@     should be specified.
     *\@\@
     *
     * Generated from protobuf field <code>string platform = 2;</code>
     */
    protected $platform = '';
    /**
     *\@\@  .. cpp:var:: string backend
     *\@\@
     *\@\@     The backend used by the model.
     *\@\@
     *
     * Generated from protobuf field <code>string backend = 17;</code>
     */
    protected $backend = '';
    /**
     *\@\@  .. cpp:var:: string runtime
     *\@\@
     *\@\@     The name of the backend library file used by the model.
     *\@\@
     *
     * Generated from protobuf field <code>string runtime = 25;</code>
     */
    protected $runtime = '';
    /**
     *\@\@  .. cpp:var:: ModelVersionPolicy version_policy
     *\@\@
     *\@\@     Policy indicating which version(s) of the model will be served.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelVersionPolicy version_policy = 3;</code>
     */
    protected $version_policy = null;
    /**
     *\@\@  .. cpp:var:: int32 max_batch_size
     *\@\@
     *\@\@     Maximum batch size allowed for inference. This can only decrease
     *\@\@     what is allowed by the model itself. A max_batch_size value of 0
     *\@\@     indicates that batching is not allowed for the model and the
     *\@\@     dimension/shape of the input and output tensors must exactly
     *\@\@     match what is specified in the input and output configuration. A
     *\@\@     max_batch_size value > 0 indicates that batching is allowed and
     *\@\@     so the model expects the input tensors to have an additional
     *\@\@     initial dimension for the batching that is not specified in the
     *\@\@     input (for example, if the model supports batched inputs of
     *\@\@     2-dimensional tensors then the model configuration will specify
     *\@\@     the input shape as [ X, Y ] but the model will expect the actual
     *\@\@     input tensors to have shape [ N, X, Y ]). For max_batch_size > 0
     *\@\@     returned outputs will also have an additional initial dimension
     *\@\@     for the batch.
     *\@\@
     *
     * Generated from protobuf field <code>int32 max_batch_size = 4;</code>
     */
    protected $max_batch_size = 0;
    /**
     *\@\@  .. cpp:var:: ModelInput input (repeated)
     *\@\@
     *\@\@     The inputs request by the model.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelInput input = 5;</code>
     */
    private $input;
    /**
     *\@\@  .. cpp:var:: ModelOutput output (repeated)
     *\@\@
     *\@\@     The outputs produced by the model.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelOutput output = 6;</code>
     */
    private $output;
    /**
     *\@\@  .. cpp:var:: BatchInput batch_input (repeated)
     *\@\@
     *\@\@     The model input(s) that the server should use to communicate
     *\@\@     batch related values to the model.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.BatchInput batch_input = 20;</code>
     */
    private $batch_input;
    /**
     *\@\@  .. cpp:var:: BatchOutput batch_output (repeated)
     *\@\@
     *\@\@     The outputs produced by the model that requires special handling
     *\@\@     by the model backend.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.BatchOutput batch_output = 21;</code>
     */
    private $batch_output;
    /**
     *\@\@  .. cpp:var:: ModelOptimizationPolicy optimization
     *\@\@
     *\@\@     Optimization configuration for the model. If not specified
     *\@\@     then default optimization policy is used.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelOptimizationPolicy optimization = 12;</code>
     */
    protected $optimization = null;
    /**
     *\@\@  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *\@\@
     *\@\@     Instances of this model. If not specified, one instance
     *\@\@     of the model will be instantiated on each available GPU.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     */
    private $instance_group;
    /**
     *\@\@  .. cpp:var:: string default_model_filename
     *\@\@
     *\@\@     Optional filename of the model file to use if a
     *\@\@     compute-capability specific model is not specified in
     *\@\@     :cpp:var:`cc_model_filenames`. If not specified the default name
     *\@\@     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
     *\@\@     'model.pt' depending on the model type.
     *\@\@
     *
     * Generated from protobuf field <code>string default_model_filename = 8;</code>
     */
    protected $default_model_filename = '';
    /**
     *\@\@  .. cpp:var:: map<string,string> cc_model_filenames
     *\@\@
     *\@\@     Optional map from CUDA compute capability to the filename of
     *\@\@     the model that supports that compute capability. The filename
     *\@\@     refers to a file within the model version directory.
     *\@\@
     *
     * Generated from protobuf field <code>map<string, string> cc_model_filenames = 9;</code>
     */
    private $cc_model_filenames;
    /**
     *\@\@  .. cpp:var:: map<string,string> metric_tags
     *\@\@
     *\@\@     Optional metric tags. User-specific key-value pairs for metrics
     *\@\@     reported for this model. These tags are applied to the metrics
     *\@\@     reported on the HTTP metrics port.
     *\@\@
     *
     * Generated from protobuf field <code>map<string, string> metric_tags = 10;</code>
     */
    private $metric_tags;
    /**
     *\@\@  .. cpp:var:: map<string,ModelParameter> parameters
     *\@\@
     *\@\@     Optional model parameters. User-specified parameter values.
     *\@\@
     *
     * Generated from protobuf field <code>map<string, .inference.ModelParameter> parameters = 14;</code>
     */
    private $parameters;
    /**
     *\@\@  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *\@\@
     *\@\@     Warmup setting of this model. If specified, all instances
     *\@\@     will be run with the request samples in sequence before
     *\@\@     serving the model.
     *\@\@     This field can only be specified if the model is not an ensemble
     *\@\@     model.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     */
    private $model_warmup;
    /**
     *\@\@  .. cpp:var:: ModelOperations model_operations
     *\@\@
     *\@\@     Optional metadata of the libraries providing custom operations for
     *\@\@     this model.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelOperations model_operations = 18;</code>
     */
    protected $model_operations = null;
    /**
     *\@\@  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *\@\@
     *\@\@     Optional specification that describes the nature of transactions
     *\@\@     to be expected from the model.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
     */
    protected $model_transaction_policy = null;
    /**
     *\@\@  .. cpp:var:: ModelRepositoryAgents model_repository_agents
     *\@\@
     *\@\@     Optional specification of the agent(s) that should be invoked
     *\@\@     with repository actions are performed for this model.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelRepositoryAgents model_repository_agents = 23;</code>
     */
    protected $model_repository_agents = null;
    /**
     *\@\@  .. cpp:var:: ModelResponseCache response_cache
     *\@\@
     *\@\@     Optional setting for utilizing the response cache for this
     *\@\@     model.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelResponseCache response_cache = 24;</code>
     */
    protected $response_cache = null;
    /**
     *\@\@  .. cpp:var:: ModelMetrics model_metrics
     *\@\@
     *\@\@     Optional setting for custom metrics configuration for this model.
     *\@\@     Application default is applied to metrics that are not specified.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelMetrics model_metrics = 26;</code>
     */
    protected $model_metrics = null;
    protected $scheduling_choice;

    /**
     * Constructor.
     *
     * @param array $data {
     *     Optional. Data for populating the Message object.
     *
     *     @type string $name
     *          \@\@  .. cpp:var:: string name
     *          \@\@
     *          \@\@     The name of the model.
     *          \@\@
     *     @type string $platform
     *          \@\@  .. cpp:var:: string platform
     *          \@\@
     *          \@\@     Additional backend-specific configuration for the model.
     *          \@\@     Please refer to the backend documentation on whether this field
     *          \@\@     should be specified.
     *          \@\@
     *     @type string $backend
     *          \@\@  .. cpp:var:: string backend
     *          \@\@
     *          \@\@     The backend used by the model.
     *          \@\@
     *     @type string $runtime
     *          \@\@  .. cpp:var:: string runtime
     *          \@\@
     *          \@\@     The name of the backend library file used by the model.
     *          \@\@
     *     @type \Inference\ModelVersionPolicy $version_policy
     *          \@\@  .. cpp:var:: ModelVersionPolicy version_policy
     *          \@\@
     *          \@\@     Policy indicating which version(s) of the model will be served.
     *          \@\@
     *     @type int $max_batch_size
     *          \@\@  .. cpp:var:: int32 max_batch_size
     *          \@\@
     *          \@\@     Maximum batch size allowed for inference. This can only decrease
     *          \@\@     what is allowed by the model itself. A max_batch_size value of 0
     *          \@\@     indicates that batching is not allowed for the model and the
     *          \@\@     dimension/shape of the input and output tensors must exactly
     *          \@\@     match what is specified in the input and output configuration. A
     *          \@\@     max_batch_size value > 0 indicates that batching is allowed and
     *          \@\@     so the model expects the input tensors to have an additional
     *          \@\@     initial dimension for the batching that is not specified in the
     *          \@\@     input (for example, if the model supports batched inputs of
     *          \@\@     2-dimensional tensors then the model configuration will specify
     *          \@\@     the input shape as [ X, Y ] but the model will expect the actual
     *          \@\@     input tensors to have shape [ N, X, Y ]). For max_batch_size > 0
     *          \@\@     returned outputs will also have an additional initial dimension
     *          \@\@     for the batch.
     *          \@\@
     *     @type \Inference\ModelInput[] $input
     *          \@\@  .. cpp:var:: ModelInput input (repeated)
     *          \@\@
     *          \@\@     The inputs request by the model.
     *          \@\@
     *     @type \Inference\ModelOutput[] $output
     *          \@\@  .. cpp:var:: ModelOutput output (repeated)
     *          \@\@
     *          \@\@     The outputs produced by the model.
     *          \@\@
     *     @type \Inference\BatchInput[] $batch_input
     *          \@\@  .. cpp:var:: BatchInput batch_input (repeated)
     *          \@\@
     *          \@\@     The model input(s) that the server should use to communicate
     *          \@\@     batch related values to the model.
     *          \@\@
     *     @type \Inference\BatchOutput[] $batch_output
     *          \@\@  .. cpp:var:: BatchOutput batch_output (repeated)
     *          \@\@
     *          \@\@     The outputs produced by the model that requires special handling
     *          \@\@     by the model backend.
     *          \@\@
     *     @type \Inference\ModelOptimizationPolicy $optimization
     *          \@\@  .. cpp:var:: ModelOptimizationPolicy optimization
     *          \@\@
     *          \@\@     Optimization configuration for the model. If not specified
     *          \@\@     then default optimization policy is used.
     *          \@\@
     *     @type \Inference\ModelDynamicBatching $dynamic_batching
     *          \@\@    .. cpp:var:: ModelDynamicBatching dynamic_batching
     *          \@\@
     *          \@\@       If specified, enables the dynamic-batching scheduling
     *          \@\@       policy. With dynamic-batching the scheduler may group
     *          \@\@       together independent requests into a single batch to
     *          \@\@       improve inference throughput.
     *          \@\@
     *     @type \Inference\ModelSequenceBatching $sequence_batching
     *          \@\@    .. cpp:var:: ModelSequenceBatching sequence_batching
     *          \@\@
     *          \@\@       If specified, enables the sequence-batching scheduling
     *          \@\@       policy. With sequence-batching, inference requests
     *          \@\@       with the same correlation ID are routed to the same
     *          \@\@       model instance. Multiple sequences of inference requests
     *          \@\@       may be batched together into a single batch to
     *          \@\@       improve inference throughput.
     *          \@\@
     *     @type \Inference\ModelEnsembling $ensemble_scheduling
     *          \@\@    .. cpp:var:: ModelEnsembling ensemble_scheduling
     *          \@\@
     *          \@\@       If specified, enables the model-ensembling scheduling
     *          \@\@       policy. With model-ensembling, inference requests
     *          \@\@       will be processed according to the specification, such as an
     *          \@\@       execution sequence of models. The input specified in this model
     *          \@\@       config will be the input for the ensemble, and the output
     *          \@\@       specified will be the output of the ensemble.
     *          \@\@
     *     @type \Inference\ModelInstanceGroup[] $instance_group
     *          \@\@  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *          \@\@
     *          \@\@     Instances of this model. If not specified, one instance
     *          \@\@     of the model will be instantiated on each available GPU.
     *          \@\@
     *     @type string $default_model_filename
     *          \@\@  .. cpp:var:: string default_model_filename
     *          \@\@
     *          \@\@     Optional filename of the model file to use if a
     *          \@\@     compute-capability specific model is not specified in
     *          \@\@     :cpp:var:`cc_model_filenames`. If not specified the default name
     *          \@\@     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
     *          \@\@     'model.pt' depending on the model type.
     *          \@\@
     *     @type array|\Google\Protobuf\Internal\MapField $cc_model_filenames
     *          \@\@  .. cpp:var:: map<string,string> cc_model_filenames
     *          \@\@
     *          \@\@     Optional map from CUDA compute capability to the filename of
     *          \@\@     the model that supports that compute capability. The filename
     *          \@\@     refers to a file within the model version directory.
     *          \@\@
     *     @type array|\Google\Protobuf\Internal\MapField $metric_tags
     *          \@\@  .. cpp:var:: map<string,string> metric_tags
     *          \@\@
     *          \@\@     Optional metric tags. User-specific key-value pairs for metrics
     *          \@\@     reported for this model. These tags are applied to the metrics
     *          \@\@     reported on the HTTP metrics port.
     *          \@\@
     *     @type array|\Google\Protobuf\Internal\MapField $parameters
     *          \@\@  .. cpp:var:: map<string,ModelParameter> parameters
     *          \@\@
     *          \@\@     Optional model parameters. User-specified parameter values.
     *          \@\@
     *     @type \Inference\ModelWarmup[] $model_warmup
     *          \@\@  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *          \@\@
     *          \@\@     Warmup setting of this model. If specified, all instances
     *          \@\@     will be run with the request samples in sequence before
     *          \@\@     serving the model.
     *          \@\@     This field can only be specified if the model is not an ensemble
     *          \@\@     model.
     *          \@\@
     *     @type \Inference\ModelOperations $model_operations
     *          \@\@  .. cpp:var:: ModelOperations model_operations
     *          \@\@
     *          \@\@     Optional metadata of the libraries providing custom operations for
     *          \@\@     this model.
     *          \@\@
     *     @type \Inference\ModelTransactionPolicy $model_transaction_policy
     *          \@\@  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *          \@\@
     *          \@\@     Optional specification that describes the nature of transactions
     *          \@\@     to be expected from the model.
     *          \@\@
     *     @type \Inference\ModelRepositoryAgents $model_repository_agents
     *          \@\@  .. cpp:var:: ModelRepositoryAgents model_repository_agents
     *          \@\@
     *          \@\@     Optional specification of the agent(s) that should be invoked
     *          \@\@     with repository actions are performed for this model.
     *          \@\@
     *     @type \Inference\ModelResponseCache $response_cache
     *          \@\@  .. cpp:var:: ModelResponseCache response_cache
     *          \@\@
     *          \@\@     Optional setting for utilizing the response cache for this
     *          \@\@     model.
     *          \@\@
     *     @type \Inference\ModelMetrics $model_metrics
     *          \@\@  .. cpp:var:: ModelMetrics model_metrics
     *          \@\@
     *          \@\@     Optional setting for custom metrics configuration for this model.
     *          \@\@     Application default is applied to metrics that are not specified.
     *          \@\@
     * }
     */
    public function __construct($data = NULL) {
        \GPBMetadata\ModelConfig::initOnce();
        parent::__construct($data);
    }

    /**
     *\@\@  .. cpp:var:: string name
     *\@\@
     *\@\@     The name of the model.
     *\@\@
     *
     * Generated from protobuf field <code>string name = 1;</code>
     * @return string
     */
    public function getName()
    {
        return $this->name;
    }

    /**
     *\@\@  .. cpp:var:: string name
     *\@\@
     *\@\@     The name of the model.
     *\@\@
     *
     * Generated from protobuf field <code>string name = 1;</code>
     * @param string $var
     * @return $this
     */
    public function setName($var)
    {
        GPBUtil::checkString($var, True);
        $this->name = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: string platform
     *\@\@
     *\@\@     Additional backend-specific configuration for the model.
     *\@\@     Please refer to the backend documentation on whether this field
     *\@\@     should be specified.
     *\@\@
     *
     * Generated from protobuf field <code>string platform = 2;</code>
     * @return string
     */
    public function getPlatform()
    {
        return $this->platform;
    }

    /**
     *\@\@  .. cpp:var:: string platform
     *\@\@
     *\@\@     Additional backend-specific configuration for the model.
     *\@\@     Please refer to the backend documentation on whether this field
     *\@\@     should be specified.
     *\@\@
     *
     * Generated from protobuf field <code>string platform = 2;</code>
     * @param string $var
     * @return $this
     */
    public function setPlatform($var)
    {
        GPBUtil::checkString($var, True);
        $this->platform = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: string backend
     *\@\@
     *\@\@     The backend used by the model.
     *\@\@
     *
     * Generated from protobuf field <code>string backend = 17;</code>
     * @return string
     */
    public function getBackend()
    {
        return $this->backend;
    }

    /**
     *\@\@  .. cpp:var:: string backend
     *\@\@
     *\@\@     The backend used by the model.
     *\@\@
     *
     * Generated from protobuf field <code>string backend = 17;</code>
     * @param string $var
     * @return $this
     */
    public function setBackend($var)
    {
        GPBUtil::checkString($var, True);
        $this->backend = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: string runtime
     *\@\@
     *\@\@     The name of the backend library file used by the model.
     *\@\@
     *
     * Generated from protobuf field <code>string runtime = 25;</code>
     * @return string
     */
    public function getRuntime()
    {
        return $this->runtime;
    }

    /**
     *\@\@  .. cpp:var:: string runtime
     *\@\@
     *\@\@     The name of the backend library file used by the model.
     *\@\@
     *
     * Generated from protobuf field <code>string runtime = 25;</code>
     * @param string $var
     * @return $this
     */
    public function setRuntime($var)
    {
        GPBUtil::checkString($var, True);
        $this->runtime = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: ModelVersionPolicy version_policy
     *\@\@
     *\@\@     Policy indicating which version(s) of the model will be served.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelVersionPolicy version_policy = 3;</code>
     * @return \Inference\ModelVersionPolicy|null
     */
    public function getVersionPolicy()
    {
        return $this->version_policy;
    }

    public function hasVersionPolicy()
    {
        return isset($this->version_policy);
    }

    public function clearVersionPolicy()
    {
        unset($this->version_policy);
    }

    /**
     *\@\@  .. cpp:var:: ModelVersionPolicy version_policy
     *\@\@
     *\@\@     Policy indicating which version(s) of the model will be served.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelVersionPolicy version_policy = 3;</code>
     * @param \Inference\ModelVersionPolicy $var
     * @return $this
     */
    public function setVersionPolicy($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelVersionPolicy::class);
        $this->version_policy = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: int32 max_batch_size
     *\@\@
     *\@\@     Maximum batch size allowed for inference. This can only decrease
     *\@\@     what is allowed by the model itself. A max_batch_size value of 0
     *\@\@     indicates that batching is not allowed for the model and the
     *\@\@     dimension/shape of the input and output tensors must exactly
     *\@\@     match what is specified in the input and output configuration. A
     *\@\@     max_batch_size value > 0 indicates that batching is allowed and
     *\@\@     so the model expects the input tensors to have an additional
     *\@\@     initial dimension for the batching that is not specified in the
     *\@\@     input (for example, if the model supports batched inputs of
     *\@\@     2-dimensional tensors then the model configuration will specify
     *\@\@     the input shape as [ X, Y ] but the model will expect the actual
     *\@\@     input tensors to have shape [ N, X, Y ]). For max_batch_size > 0
     *\@\@     returned outputs will also have an additional initial dimension
     *\@\@     for the batch.
     *\@\@
     *
     * Generated from protobuf field <code>int32 max_batch_size = 4;</code>
     * @return int
     */
    public function getMaxBatchSize()
    {
        return $this->max_batch_size;
    }

    /**
     *\@\@  .. cpp:var:: int32 max_batch_size
     *\@\@
     *\@\@     Maximum batch size allowed for inference. This can only decrease
     *\@\@     what is allowed by the model itself. A max_batch_size value of 0
     *\@\@     indicates that batching is not allowed for the model and the
     *\@\@     dimension/shape of the input and output tensors must exactly
     *\@\@     match what is specified in the input and output configuration. A
     *\@\@     max_batch_size value > 0 indicates that batching is allowed and
     *\@\@     so the model expects the input tensors to have an additional
     *\@\@     initial dimension for the batching that is not specified in the
     *\@\@     input (for example, if the model supports batched inputs of
     *\@\@     2-dimensional tensors then the model configuration will specify
     *\@\@     the input shape as [ X, Y ] but the model will expect the actual
     *\@\@     input tensors to have shape [ N, X, Y ]). For max_batch_size > 0
     *\@\@     returned outputs will also have an additional initial dimension
     *\@\@     for the batch.
     *\@\@
     *
     * Generated from protobuf field <code>int32 max_batch_size = 4;</code>
     * @param int $var
     * @return $this
     */
    public function setMaxBatchSize($var)
    {
        GPBUtil::checkInt32($var);
        $this->max_batch_size = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: ModelInput input (repeated)
     *\@\@
     *\@\@     The inputs request by the model.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelInput input = 5;</code>
     * @return RepeatedField<\Inference\ModelInput>
     */
    public function getInput()
    {
        return $this->input;
    }

    /**
     *\@\@  .. cpp:var:: ModelInput input (repeated)
     *\@\@
     *\@\@     The inputs request by the model.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelInput input = 5;</code>
     * @param \Inference\ModelInput[] $var
     * @return $this
     */
    public function setInput($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\ModelInput::class);
        $this->input = $arr;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: ModelOutput output (repeated)
     *\@\@
     *\@\@     The outputs produced by the model.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelOutput output = 6;</code>
     * @return RepeatedField<\Inference\ModelOutput>
     */
    public function getOutput()
    {
        return $this->output;
    }

    /**
     *\@\@  .. cpp:var:: ModelOutput output (repeated)
     *\@\@
     *\@\@     The outputs produced by the model.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelOutput output = 6;</code>
     * @param \Inference\ModelOutput[] $var
     * @return $this
     */
    public function setOutput($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\ModelOutput::class);
        $this->output = $arr;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: BatchInput batch_input (repeated)
     *\@\@
     *\@\@     The model input(s) that the server should use to communicate
     *\@\@     batch related values to the model.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.BatchInput batch_input = 20;</code>
     * @return RepeatedField<\Inference\BatchInput>
     */
    public function getBatchInput()
    {
        return $this->batch_input;
    }

    /**
     *\@\@  .. cpp:var:: BatchInput batch_input (repeated)
     *\@\@
     *\@\@     The model input(s) that the server should use to communicate
     *\@\@     batch related values to the model.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.BatchInput batch_input = 20;</code>
     * @param \Inference\BatchInput[] $var
     * @return $this
     */
    public function setBatchInput($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\BatchInput::class);
        $this->batch_input = $arr;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: BatchOutput batch_output (repeated)
     *\@\@
     *\@\@     The outputs produced by the model that requires special handling
     *\@\@     by the model backend.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.BatchOutput batch_output = 21;</code>
     * @return RepeatedField<\Inference\BatchOutput>
     */
    public function getBatchOutput()
    {
        return $this->batch_output;
    }

    /**
     *\@\@  .. cpp:var:: BatchOutput batch_output (repeated)
     *\@\@
     *\@\@     The outputs produced by the model that requires special handling
     *\@\@     by the model backend.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.BatchOutput batch_output = 21;</code>
     * @param \Inference\BatchOutput[] $var
     * @return $this
     */
    public function setBatchOutput($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\BatchOutput::class);
        $this->batch_output = $arr;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: ModelOptimizationPolicy optimization
     *\@\@
     *\@\@     Optimization configuration for the model. If not specified
     *\@\@     then default optimization policy is used.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelOptimizationPolicy optimization = 12;</code>
     * @return \Inference\ModelOptimizationPolicy|null
     */
    public function getOptimization()
    {
        return $this->optimization;
    }

    public function hasOptimization()
    {
        return isset($this->optimization);
    }

    public function clearOptimization()
    {
        unset($this->optimization);
    }

    /**
     *\@\@  .. cpp:var:: ModelOptimizationPolicy optimization
     *\@\@
     *\@\@     Optimization configuration for the model. If not specified
     *\@\@     then default optimization policy is used.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelOptimizationPolicy optimization = 12;</code>
     * @param \Inference\ModelOptimizationPolicy $var
     * @return $this
     */
    public function setOptimization($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelOptimizationPolicy::class);
        $this->optimization = $var;

        return $this;
    }

    /**
     *\@\@    .. cpp:var:: ModelDynamicBatching dynamic_batching
     *\@\@
     *\@\@       If specified, enables the dynamic-batching scheduling
     *\@\@       policy. With dynamic-batching the scheduler may group
     *\@\@       together independent requests into a single batch to
     *\@\@       improve inference throughput.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelDynamicBatching dynamic_batching = 11;</code>
     * @return \Inference\ModelDynamicBatching|null
     */
    public function getDynamicBatching()
    {
        return $this->readOneof(11);
    }

    public function hasDynamicBatching()
    {
        return $this->hasOneof(11);
    }

    /**
     *\@\@    .. cpp:var:: ModelDynamicBatching dynamic_batching
     *\@\@
     *\@\@       If specified, enables the dynamic-batching scheduling
     *\@\@       policy. With dynamic-batching the scheduler may group
     *\@\@       together independent requests into a single batch to
     *\@\@       improve inference throughput.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelDynamicBatching dynamic_batching = 11;</code>
     * @param \Inference\ModelDynamicBatching $var
     * @return $this
     */
    public function setDynamicBatching($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelDynamicBatching::class);
        $this->writeOneof(11, $var);

        return $this;
    }

    /**
     *\@\@    .. cpp:var:: ModelSequenceBatching sequence_batching
     *\@\@
     *\@\@       If specified, enables the sequence-batching scheduling
     *\@\@       policy. With sequence-batching, inference requests
     *\@\@       with the same correlation ID are routed to the same
     *\@\@       model instance. Multiple sequences of inference requests
     *\@\@       may be batched together into a single batch to
     *\@\@       improve inference throughput.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelSequenceBatching sequence_batching = 13;</code>
     * @return \Inference\ModelSequenceBatching|null
     */
    public function getSequenceBatching()
    {
        return $this->readOneof(13);
    }

    public function hasSequenceBatching()
    {
        return $this->hasOneof(13);
    }

    /**
     *\@\@    .. cpp:var:: ModelSequenceBatching sequence_batching
     *\@\@
     *\@\@       If specified, enables the sequence-batching scheduling
     *\@\@       policy. With sequence-batching, inference requests
     *\@\@       with the same correlation ID are routed to the same
     *\@\@       model instance. Multiple sequences of inference requests
     *\@\@       may be batched together into a single batch to
     *\@\@       improve inference throughput.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelSequenceBatching sequence_batching = 13;</code>
     * @param \Inference\ModelSequenceBatching $var
     * @return $this
     */
    public function setSequenceBatching($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelSequenceBatching::class);
        $this->writeOneof(13, $var);

        return $this;
    }

    /**
     *\@\@    .. cpp:var:: ModelEnsembling ensemble_scheduling
     *\@\@
     *\@\@       If specified, enables the model-ensembling scheduling
     *\@\@       policy. With model-ensembling, inference requests
     *\@\@       will be processed according to the specification, such as an
     *\@\@       execution sequence of models. The input specified in this model
     *\@\@       config will be the input for the ensemble, and the output
     *\@\@       specified will be the output of the ensemble.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelEnsembling ensemble_scheduling = 15;</code>
     * @return \Inference\ModelEnsembling|null
     */
    public function getEnsembleScheduling()
    {
        return $this->readOneof(15);
    }

    public function hasEnsembleScheduling()
    {
        return $this->hasOneof(15);
    }

    /**
     *\@\@    .. cpp:var:: ModelEnsembling ensemble_scheduling
     *\@\@
     *\@\@       If specified, enables the model-ensembling scheduling
     *\@\@       policy. With model-ensembling, inference requests
     *\@\@       will be processed according to the specification, such as an
     *\@\@       execution sequence of models. The input specified in this model
     *\@\@       config will be the input for the ensemble, and the output
     *\@\@       specified will be the output of the ensemble.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelEnsembling ensemble_scheduling = 15;</code>
     * @param \Inference\ModelEnsembling $var
     * @return $this
     */
    public function setEnsembleScheduling($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelEnsembling::class);
        $this->writeOneof(15, $var);

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *\@\@
     *\@\@     Instances of this model. If not specified, one instance
     *\@\@     of the model will be instantiated on each available GPU.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     * @return RepeatedField<\Inference\ModelInstanceGroup>
     */
    public function getInstanceGroup()
    {
        return $this->instance_group;
    }

    /**
     *\@\@  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *\@\@
     *\@\@     Instances of this model. If not specified, one instance
     *\@\@     of the model will be instantiated on each available GPU.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     * @param \Inference\ModelInstanceGroup[] $var
     * @return $this
     */
    public function setInstanceGroup($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\ModelInstanceGroup::class);
        $this->instance_group = $arr;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: string default_model_filename
     *\@\@
     *\@\@     Optional filename of the model file to use if a
     *\@\@     compute-capability specific model is not specified in
     *\@\@     :cpp:var:`cc_model_filenames`. If not specified the default name
     *\@\@     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
     *\@\@     'model.pt' depending on the model type.
     *\@\@
     *
     * Generated from protobuf field <code>string default_model_filename = 8;</code>
     * @return string
     */
    public function getDefaultModelFilename()
    {
        return $this->default_model_filename;
    }

    /**
     *\@\@  .. cpp:var:: string default_model_filename
     *\@\@
     *\@\@     Optional filename of the model file to use if a
     *\@\@     compute-capability specific model is not specified in
     *\@\@     :cpp:var:`cc_model_filenames`. If not specified the default name
     *\@\@     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
     *\@\@     'model.pt' depending on the model type.
     *\@\@
     *
     * Generated from protobuf field <code>string default_model_filename = 8;</code>
     * @param string $var
     * @return $this
     */
    public function setDefaultModelFilename($var)
    {
        GPBUtil::checkString($var, True);
        $this->default_model_filename = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: map<string,string> cc_model_filenames
     *\@\@
     *\@\@     Optional map from CUDA compute capability to the filename of
     *\@\@     the model that supports that compute capability. The filename
     *\@\@     refers to a file within the model version directory.
     *\@\@
     *
     * Generated from protobuf field <code>map<string, string> cc_model_filenames = 9;</code>
     * @return \Google\Protobuf\Internal\MapField
     */
    public function getCcModelFilenames()
    {
        return $this->cc_model_filenames;
    }

    /**
     *\@\@  .. cpp:var:: map<string,string> cc_model_filenames
     *\@\@
     *\@\@     Optional map from CUDA compute capability to the filename of
     *\@\@     the model that supports that compute capability. The filename
     *\@\@     refers to a file within the model version directory.
     *\@\@
     *
     * Generated from protobuf field <code>map<string, string> cc_model_filenames = 9;</code>
     * @param array|\Google\Protobuf\Internal\MapField $var
     * @return $this
     */
    public function setCcModelFilenames($var)
    {
        $arr = GPBUtil::checkMapField($var, \Google\Protobuf\Internal\GPBType::STRING, \Google\Protobuf\Internal\GPBType::STRING);
        $this->cc_model_filenames = $arr;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: map<string,string> metric_tags
     *\@\@
     *\@\@     Optional metric tags. User-specific key-value pairs for metrics
     *\@\@     reported for this model. These tags are applied to the metrics
     *\@\@     reported on the HTTP metrics port.
     *\@\@
     *
     * Generated from protobuf field <code>map<string, string> metric_tags = 10;</code>
     * @return \Google\Protobuf\Internal\MapField
     */
    public function getMetricTags()
    {
        return $this->metric_tags;
    }

    /**
     *\@\@  .. cpp:var:: map<string,string> metric_tags
     *\@\@
     *\@\@     Optional metric tags. User-specific key-value pairs for metrics
     *\@\@     reported for this model. These tags are applied to the metrics
     *\@\@     reported on the HTTP metrics port.
     *\@\@
     *
     * Generated from protobuf field <code>map<string, string> metric_tags = 10;</code>
     * @param array|\Google\Protobuf\Internal\MapField $var
     * @return $this
     */
    public function setMetricTags($var)
    {
        $arr = GPBUtil::checkMapField($var, \Google\Protobuf\Internal\GPBType::STRING, \Google\Protobuf\Internal\GPBType::STRING);
        $this->metric_tags = $arr;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: map<string,ModelParameter> parameters
     *\@\@
     *\@\@     Optional model parameters. User-specified parameter values.
     *\@\@
     *
     * Generated from protobuf field <code>map<string, .inference.ModelParameter> parameters = 14;</code>
     * @return \Google\Protobuf\Internal\MapField
     */
    public function getParameters()
    {
        return $this->parameters;
    }

    /**
     *\@\@  .. cpp:var:: map<string,ModelParameter> parameters
     *\@\@
     *\@\@     Optional model parameters. User-specified parameter values.
     *\@\@
     *
     * Generated from protobuf field <code>map<string, .inference.ModelParameter> parameters = 14;</code>
     * @param array|\Google\Protobuf\Internal\MapField $var
     * @return $this
     */
    public function setParameters($var)
    {
        $arr = GPBUtil::checkMapField($var, \Google\Protobuf\Internal\GPBType::STRING, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\ModelParameter::class);
        $this->parameters = $arr;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *\@\@
     *\@\@     Warmup setting of this model. If specified, all instances
     *\@\@     will be run with the request samples in sequence before
     *\@\@     serving the model.
     *\@\@     This field can only be specified if the model is not an ensemble
     *\@\@     model.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     * @return RepeatedField<\Inference\ModelWarmup>
     */
    public function getModelWarmup()
    {
        return $this->model_warmup;
    }

    /**
     *\@\@  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *\@\@
     *\@\@     Warmup setting of this model. If specified, all instances
     *\@\@     will be run with the request samples in sequence before
     *\@\@     serving the model.
     *\@\@     This field can only be specified if the model is not an ensemble
     *\@\@     model.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     * @param \Inference\ModelWarmup[] $var
     * @return $this
     */
    public function setModelWarmup($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\ModelWarmup::class);
        $this->model_warmup = $arr;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: ModelOperations model_operations
     *\@\@
     *\@\@     Optional metadata of the libraries providing custom operations for
     *\@\@     this model.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelOperations model_operations = 18;</code>
     * @return \Inference\ModelOperations|null
     */
    public function getModelOperations()
    {
        return $this->model_operations;
    }

    public function hasModelOperations()
    {
        return isset($this->model_operations);
    }

    public function clearModelOperations()
    {
        unset($this->model_operations);
    }

    /**
     *\@\@  .. cpp:var:: ModelOperations model_operations
     *\@\@
     *\@\@     Optional metadata of the libraries providing custom operations for
     *\@\@     this model.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelOperations model_operations = 18;</code>
     * @param \Inference\ModelOperations $var
     * @return $this
     */
    public function setModelOperations($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelOperations::class);
        $this->model_operations = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *\@\@
     *\@\@     Optional specification that describes the nature of transactions
     *\@\@     to be expected from the model.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
     * @return \Inference\ModelTransactionPolicy|null
     */
    public function getModelTransactionPolicy()
    {
        return $this->model_transaction_policy;
    }

    public function hasModelTransactionPolicy()
    {
        return isset($this->model_transaction_policy);
    }

    public function clearModelTransactionPolicy()
    {
        unset($this->model_transaction_policy);
    }

    /**
     *\@\@  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *\@\@
     *\@\@     Optional specification that describes the nature of transactions
     *\@\@     to be expected from the model.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
     * @param \Inference\ModelTransactionPolicy $var
     * @return $this
     */
    public function setModelTransactionPolicy($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelTransactionPolicy::class);
        $this->model_transaction_policy = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: ModelRepositoryAgents model_repository_agents
     *\@\@
     *\@\@     Optional specification of the agent(s) that should be invoked
     *\@\@     with repository actions are performed for this model.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelRepositoryAgents model_repository_agents = 23;</code>
     * @return \Inference\ModelRepositoryAgents|null
     */
    public function getModelRepositoryAgents()
    {
        return $this->model_repository_agents;
    }

    public function hasModelRepositoryAgents()
    {
        return isset($this->model_repository_agents);
    }

    public function clearModelRepositoryAgents()
    {
        unset($this->model_repository_agents);
    }

    /**
     *\@\@  .. cpp:var:: ModelRepositoryAgents model_repository_agents
     *\@\@
     *\@\@     Optional specification of the agent(s) that should be invoked
     *\@\@     with repository actions are performed for this model.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelRepositoryAgents model_repository_agents = 23;</code>
     * @param \Inference\ModelRepositoryAgents $var
     * @return $this
     */
    public function setModelRepositoryAgents($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelRepositoryAgents::class);
        $this->model_repository_agents = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: ModelResponseCache response_cache
     *\@\@
     *\@\@     Optional setting for utilizing the response cache for this
     *\@\@     model.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelResponseCache response_cache = 24;</code>
     * @return \Inference\ModelResponseCache|null
     */
    public function getResponseCache()
    {
        return $this->response_cache;
    }

    public function hasResponseCache()
    {
        return isset($this->response_cache);
    }

    public function clearResponseCache()
    {
        unset($this->response_cache);
    }

    /**
     *\@\@  .. cpp:var:: ModelResponseCache response_cache
     *\@\@
     *\@\@     Optional setting for utilizing the response cache for this
     *\@\@     model.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelResponseCache response_cache = 24;</code>
     * @param \Inference\ModelResponseCache $var
     * @return $this
     */
    public function setResponseCache($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelResponseCache::class);
        $this->response_cache = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: ModelMetrics model_metrics
     *\@\@
     *\@\@     Optional setting for custom metrics configuration for this model.
     *\@\@     Application default is applied to metrics that are not specified.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelMetrics model_metrics = 26;</code>
     * @return \Inference\ModelMetrics|null
     */
    public function getModelMetrics()
    {
        return $this->model_metrics;
    }

    public function hasModelMetrics()
    {
        return isset($this->model_metrics);
    }

    public function clearModelMetrics()
    {
        unset($this->model_metrics);
    }

    /**
     *\@\@  .. cpp:var:: ModelMetrics model_metrics
     *\@\@
     *\@\@     Optional setting for custom metrics configuration for this model.
     *\@\@     Application default is applied to metrics that are not specified.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelMetrics model_metrics = 26;</code>
     * @param \Inference\ModelMetrics $var
     * @return $this
     */
    public function setModelMetrics($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelMetrics::class);
        $this->model_metrics = $var;

        return $this;
    }

    /**
     * @return string
     */
    public function getSchedulingChoice()
    {
        return $this->whichOneof("scheduling_choice");
    }

}

