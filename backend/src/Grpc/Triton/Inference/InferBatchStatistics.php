<?php
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: grpc_service.proto

namespace Inference;

use Google\Protobuf\Internal\GPBType;
use Google\Protobuf\Internal\GPBUtil;
use Google\Protobuf\RepeatedField;

/**
 *\@\@
 *\@\@.. cpp:var:: message InferBatchStatistics
 *\@\@
 *\@\@   Inference batch statistics.
 *\@\@
 *
 * Generated from protobuf message <code>inference.InferBatchStatistics</code>
 */
class InferBatchStatistics extends \Google\Protobuf\Internal\Message
{
    /**
     *\@\@  .. cpp:var:: uint64 batch_size
     *\@\@
     *\@\@     The size of the batch.
     *\@\@
     *
     * Generated from protobuf field <code>uint64 batch_size = 1;</code>
     */
    protected $batch_size = 0;
    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_input
     *\@\@
     *\@\@     The count and cumulative duration to prepare input tensor data as
     *\@\@     required by the model framework / backend with the given batch size.
     *\@\@     For example, this duration should include the time to copy input
     *\@\@     tensor data to the GPU.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_input = 2;</code>
     */
    protected $compute_input = null;
    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_infer
     *\@\@
     *\@\@     The count and cumulative duration to execute the model with the given
     *\@\@     batch size.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_infer = 3;</code>
     */
    protected $compute_infer = null;
    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_output
     *\@\@
     *\@\@     The count and cumulative duration to extract output tensor data
     *\@\@     produced by the model framework / backend with the given batch size.
     *\@\@     For example, this duration should include the time to copy output
     *\@\@     tensor data from the GPU.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_output = 4;</code>
     */
    protected $compute_output = null;

    /**
     * Constructor.
     *
     * @param array $data {
     *     Optional. Data for populating the Message object.
     *
     *     @type int|string $batch_size
     *          \@\@  .. cpp:var:: uint64 batch_size
     *          \@\@
     *          \@\@     The size of the batch.
     *          \@\@
     *     @type \Inference\StatisticDuration $compute_input
     *          \@\@  .. cpp:var:: StatisticDuration compute_input
     *          \@\@
     *          \@\@     The count and cumulative duration to prepare input tensor data as
     *          \@\@     required by the model framework / backend with the given batch size.
     *          \@\@     For example, this duration should include the time to copy input
     *          \@\@     tensor data to the GPU.
     *          \@\@
     *     @type \Inference\StatisticDuration $compute_infer
     *          \@\@  .. cpp:var:: StatisticDuration compute_infer
     *          \@\@
     *          \@\@     The count and cumulative duration to execute the model with the given
     *          \@\@     batch size.
     *          \@\@
     *     @type \Inference\StatisticDuration $compute_output
     *          \@\@  .. cpp:var:: StatisticDuration compute_output
     *          \@\@
     *          \@\@     The count and cumulative duration to extract output tensor data
     *          \@\@     produced by the model framework / backend with the given batch size.
     *          \@\@     For example, this duration should include the time to copy output
     *          \@\@     tensor data from the GPU.
     *          \@\@
     * }
     */
    public function __construct($data = NULL) {
        \GPBMetadata\GrpcService::initOnce();
        parent::__construct($data);
    }

    /**
     *\@\@  .. cpp:var:: uint64 batch_size
     *\@\@
     *\@\@     The size of the batch.
     *\@\@
     *
     * Generated from protobuf field <code>uint64 batch_size = 1;</code>
     * @return int|string
     */
    public function getBatchSize()
    {
        return $this->batch_size;
    }

    /**
     *\@\@  .. cpp:var:: uint64 batch_size
     *\@\@
     *\@\@     The size of the batch.
     *\@\@
     *
     * Generated from protobuf field <code>uint64 batch_size = 1;</code>
     * @param int|string $var
     * @return $this
     */
    public function setBatchSize($var)
    {
        GPBUtil::checkUint64($var);
        $this->batch_size = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_input
     *\@\@
     *\@\@     The count and cumulative duration to prepare input tensor data as
     *\@\@     required by the model framework / backend with the given batch size.
     *\@\@     For example, this duration should include the time to copy input
     *\@\@     tensor data to the GPU.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_input = 2;</code>
     * @return \Inference\StatisticDuration|null
     */
    public function getComputeInput()
    {
        return $this->compute_input;
    }

    public function hasComputeInput()
    {
        return isset($this->compute_input);
    }

    public function clearComputeInput()
    {
        unset($this->compute_input);
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_input
     *\@\@
     *\@\@     The count and cumulative duration to prepare input tensor data as
     *\@\@     required by the model framework / backend with the given batch size.
     *\@\@     For example, this duration should include the time to copy input
     *\@\@     tensor data to the GPU.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_input = 2;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setComputeInput($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->compute_input = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_infer
     *\@\@
     *\@\@     The count and cumulative duration to execute the model with the given
     *\@\@     batch size.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_infer = 3;</code>
     * @return \Inference\StatisticDuration|null
     */
    public function getComputeInfer()
    {
        return $this->compute_infer;
    }

    public function hasComputeInfer()
    {
        return isset($this->compute_infer);
    }

    public function clearComputeInfer()
    {
        unset($this->compute_infer);
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_infer
     *\@\@
     *\@\@     The count and cumulative duration to execute the model with the given
     *\@\@     batch size.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_infer = 3;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setComputeInfer($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->compute_infer = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_output
     *\@\@
     *\@\@     The count and cumulative duration to extract output tensor data
     *\@\@     produced by the model framework / backend with the given batch size.
     *\@\@     For example, this duration should include the time to copy output
     *\@\@     tensor data from the GPU.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_output = 4;</code>
     * @return \Inference\StatisticDuration|null
     */
    public function getComputeOutput()
    {
        return $this->compute_output;
    }

    public function hasComputeOutput()
    {
        return isset($this->compute_output);
    }

    public function clearComputeOutput()
    {
        unset($this->compute_output);
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_output
     *\@\@
     *\@\@     The count and cumulative duration to extract output tensor data
     *\@\@     produced by the model framework / backend with the given batch size.
     *\@\@     For example, this duration should include the time to copy output
     *\@\@     tensor data from the GPU.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_output = 4;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setComputeOutput($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->compute_output = $var;

        return $this;
    }

}

