<?php
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: model_config.proto

namespace Inference\ModelOptimizationPolicy\Cuda;

use Google\Protobuf\Internal\GPBType;
use Google\Protobuf\Internal\GPBUtil;
use Google\Protobuf\RepeatedField;

/**
 *\@\@    .. cpp:var:: message GraphSpec
 *\@\@
 *\@\@       Specification of the CUDA graph to be captured.
 *\@\@
 *
 * Generated from protobuf message <code>inference.ModelOptimizationPolicy.Cuda.GraphSpec</code>
 */
class GraphSpec extends \Google\Protobuf\Internal\Message
{
    /**
     *\@\@      .. cpp:var:: int32 batch_size
     *\@\@
     *\@\@         The batch size of the CUDA graph. If 'max_batch_size' is 0,
     *\@\@         'batch_size' must be set to 0. Otherwise, 'batch_size' must
     *\@\@         be set to value between 1 and 'max_batch_size'.
     *\@\@
     *
     * Generated from protobuf field <code>int32 batch_size = 1;</code>
     */
    protected $batch_size = 0;
    /**
     *\@\@      .. cpp:var:: map<string, Shape> input
     *\@\@
     *\@\@         The specification of the inputs. 'Shape' is the shape of the
     *\@\@         input without batching dimension.
     *\@\@
     *
     * Generated from protobuf field <code>map<string, .inference.ModelOptimizationPolicy.Cuda.GraphSpec.Shape> input = 2;</code>
     */
    private $input;
    /**
     *\@\@      .. cpp:var:: LowerBound graph_lower_bound
     *\@\@
     *\@\@         Specify the lower bound of the CUDA graph. Optional.
     *\@\@         If specified, the graph can be used for input shapes and
     *\@\@         batch sizes that are in closed interval between the lower
     *\@\@         bound specification and graph specification. For dynamic
     *\@\@         shape model, this allows CUDA graphs to be launched
     *\@\@         frequently without capturing all possible shape combinations.
     *\@\@         However, using graph for shape combinations different from
     *\@\@         the one used for capturing introduces uninitialized data for
     *\@\@         execution and it may distort the inference result if
     *\@\@         the model is sensitive to uninitialized data.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound graph_lower_bound = 3;</code>
     */
    protected $graph_lower_bound = null;

    /**
     * Constructor.
     *
     * @param array $data {
     *     Optional. Data for populating the Message object.
     *
     *     @type int $batch_size
     *          \@\@      .. cpp:var:: int32 batch_size
     *          \@\@
     *          \@\@         The batch size of the CUDA graph. If 'max_batch_size' is 0,
     *          \@\@         'batch_size' must be set to 0. Otherwise, 'batch_size' must
     *          \@\@         be set to value between 1 and 'max_batch_size'.
     *          \@\@
     *     @type array|\Google\Protobuf\Internal\MapField $input
     *          \@\@      .. cpp:var:: map<string, Shape> input
     *          \@\@
     *          \@\@         The specification of the inputs. 'Shape' is the shape of the
     *          \@\@         input without batching dimension.
     *          \@\@
     *     @type \Inference\ModelOptimizationPolicy\Cuda\GraphSpec\LowerBound $graph_lower_bound
     *          \@\@      .. cpp:var:: LowerBound graph_lower_bound
     *          \@\@
     *          \@\@         Specify the lower bound of the CUDA graph. Optional.
     *          \@\@         If specified, the graph can be used for input shapes and
     *          \@\@         batch sizes that are in closed interval between the lower
     *          \@\@         bound specification and graph specification. For dynamic
     *          \@\@         shape model, this allows CUDA graphs to be launched
     *          \@\@         frequently without capturing all possible shape combinations.
     *          \@\@         However, using graph for shape combinations different from
     *          \@\@         the one used for capturing introduces uninitialized data for
     *          \@\@         execution and it may distort the inference result if
     *          \@\@         the model is sensitive to uninitialized data.
     *          \@\@
     * }
     */
    public function __construct($data = NULL) {
        \GPBMetadata\ModelConfig::initOnce();
        parent::__construct($data);
    }

    /**
     *\@\@      .. cpp:var:: int32 batch_size
     *\@\@
     *\@\@         The batch size of the CUDA graph. If 'max_batch_size' is 0,
     *\@\@         'batch_size' must be set to 0. Otherwise, 'batch_size' must
     *\@\@         be set to value between 1 and 'max_batch_size'.
     *\@\@
     *
     * Generated from protobuf field <code>int32 batch_size = 1;</code>
     * @return int
     */
    public function getBatchSize()
    {
        return $this->batch_size;
    }

    /**
     *\@\@      .. cpp:var:: int32 batch_size
     *\@\@
     *\@\@         The batch size of the CUDA graph. If 'max_batch_size' is 0,
     *\@\@         'batch_size' must be set to 0. Otherwise, 'batch_size' must
     *\@\@         be set to value between 1 and 'max_batch_size'.
     *\@\@
     *
     * Generated from protobuf field <code>int32 batch_size = 1;</code>
     * @param int $var
     * @return $this
     */
    public function setBatchSize($var)
    {
        GPBUtil::checkInt32($var);
        $this->batch_size = $var;

        return $this;
    }

    /**
     *\@\@      .. cpp:var:: map<string, Shape> input
     *\@\@
     *\@\@         The specification of the inputs. 'Shape' is the shape of the
     *\@\@         input without batching dimension.
     *\@\@
     *
     * Generated from protobuf field <code>map<string, .inference.ModelOptimizationPolicy.Cuda.GraphSpec.Shape> input = 2;</code>
     * @return \Google\Protobuf\Internal\MapField
     */
    public function getInput()
    {
        return $this->input;
    }

    /**
     *\@\@      .. cpp:var:: map<string, Shape> input
     *\@\@
     *\@\@         The specification of the inputs. 'Shape' is the shape of the
     *\@\@         input without batching dimension.
     *\@\@
     *
     * Generated from protobuf field <code>map<string, .inference.ModelOptimizationPolicy.Cuda.GraphSpec.Shape> input = 2;</code>
     * @param array|\Google\Protobuf\Internal\MapField $var
     * @return $this
     */
    public function setInput($var)
    {
        $arr = GPBUtil::checkMapField($var, \Google\Protobuf\Internal\GPBType::STRING, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\ModelOptimizationPolicy\Cuda\GraphSpec\Shape::class);
        $this->input = $arr;

        return $this;
    }

    /**
     *\@\@      .. cpp:var:: LowerBound graph_lower_bound
     *\@\@
     *\@\@         Specify the lower bound of the CUDA graph. Optional.
     *\@\@         If specified, the graph can be used for input shapes and
     *\@\@         batch sizes that are in closed interval between the lower
     *\@\@         bound specification and graph specification. For dynamic
     *\@\@         shape model, this allows CUDA graphs to be launched
     *\@\@         frequently without capturing all possible shape combinations.
     *\@\@         However, using graph for shape combinations different from
     *\@\@         the one used for capturing introduces uninitialized data for
     *\@\@         execution and it may distort the inference result if
     *\@\@         the model is sensitive to uninitialized data.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound graph_lower_bound = 3;</code>
     * @return \Inference\ModelOptimizationPolicy\Cuda\GraphSpec\LowerBound|null
     */
    public function getGraphLowerBound()
    {
        return $this->graph_lower_bound;
    }

    public function hasGraphLowerBound()
    {
        return isset($this->graph_lower_bound);
    }

    public function clearGraphLowerBound()
    {
        unset($this->graph_lower_bound);
    }

    /**
     *\@\@      .. cpp:var:: LowerBound graph_lower_bound
     *\@\@
     *\@\@         Specify the lower bound of the CUDA graph. Optional.
     *\@\@         If specified, the graph can be used for input shapes and
     *\@\@         batch sizes that are in closed interval between the lower
     *\@\@         bound specification and graph specification. For dynamic
     *\@\@         shape model, this allows CUDA graphs to be launched
     *\@\@         frequently without capturing all possible shape combinations.
     *\@\@         However, using graph for shape combinations different from
     *\@\@         the one used for capturing introduces uninitialized data for
     *\@\@         execution and it may distort the inference result if
     *\@\@         the model is sensitive to uninitialized data.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound graph_lower_bound = 3;</code>
     * @param \Inference\ModelOptimizationPolicy\Cuda\GraphSpec\LowerBound $var
     * @return $this
     */
    public function setGraphLowerBound($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelOptimizationPolicy\Cuda\GraphSpec\LowerBound::class);
        $this->graph_lower_bound = $var;

        return $this;
    }

}

