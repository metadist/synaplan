<?php
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: grpc_service.proto

namespace Inference;

use Google\Protobuf\Internal\GPBType;
use Google\Protobuf\Internal\GPBUtil;
use Google\Protobuf\RepeatedField;

/**
 *\@\@
 *\@\@.. cpp:var:: message InferStatistics
 *\@\@
 *\@\@   Inference statistics.
 *\@\@
 *
 * Generated from protobuf message <code>inference.InferStatistics</code>
 */
class InferStatistics extends \Google\Protobuf\Internal\Message
{
    /**
     *\@\@  .. cpp:var:: StatisticDuration success
     *\@\@
     *\@\@     Cumulative count and duration for successful inference
     *\@\@     request. The "success" count and cumulative duration includes
     *\@\@     cache hits.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration success = 1;</code>
     */
    protected $success = null;
    /**
     *\@\@  .. cpp:var:: StatisticDuration fail
     *\@\@
     *\@\@     Cumulative count and duration for failed inference
     *\@\@     request.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration fail = 2;</code>
     */
    protected $fail = null;
    /**
     *\@\@  .. cpp:var:: StatisticDuration queue
     *\@\@
     *\@\@     The count and cumulative duration that inference requests wait in
     *\@\@     scheduling or other queues. The "queue" count and cumulative
     *\@\@     duration includes cache hits.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration queue = 3;</code>
     */
    protected $queue = null;
    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_input
     *\@\@
     *\@\@     The count and cumulative duration to prepare input tensor data as
     *\@\@     required by the model framework / backend. For example, this duration
     *\@\@     should include the time to copy input tensor data to the GPU.
     *\@\@     The "compute_input" count and cumulative duration do not account for
     *\@\@     requests that were a cache hit. See the "cache_hit" field for more
     *\@\@     info.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_input = 4;</code>
     */
    protected $compute_input = null;
    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_infer
     *\@\@
     *\@\@     The count and cumulative duration to execute the model.
     *\@\@     The "compute_infer" count and cumulative duration do not account for
     *\@\@     requests that were a cache hit. See the "cache_hit" field for more
     *\@\@     info.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_infer = 5;</code>
     */
    protected $compute_infer = null;
    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_output
     *\@\@
     *\@\@     The count and cumulative duration to extract output tensor data
     *\@\@     produced by the model framework / backend. For example, this duration
     *\@\@     should include the time to copy output tensor data from the GPU.
     *\@\@     The "compute_output" count and cumulative duration do not account for
     *\@\@     requests that were a cache hit. See the "cache_hit" field for more
     *\@\@     info.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_output = 6;</code>
     */
    protected $compute_output = null;
    /**
     *\@\@  .. cpp:var:: StatisticDuration cache_hit
     *\@\@
     *\@\@     The count of response cache hits and cumulative duration to lookup
     *\@\@     and extract output tensor data from the Response Cache on a cache
     *\@\@     hit. For example, this duration should include the time to copy
     *\@\@     output tensor data from the Response Cache to the response object.
     *\@\@     On cache hits, triton does not need to go to the model/backend
     *\@\@     for the output tensor data, so the "compute_input", "compute_infer",
     *\@\@     and "compute_output" fields are not updated. Assuming the response
     *\@\@     cache is enabled for a given model, a cache hit occurs for a
     *\@\@     request to that model when the request metadata (model name,
     *\@\@     model version, model inputs) hashes to an existing entry in the
     *\@\@     cache. On a cache miss, the request hash and response output tensor
     *\@\@     data is added to the cache. See response cache docs for more info:
     *\@\@
     * https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration cache_hit = 7;</code>
     */
    protected $cache_hit = null;
    /**
     *\@\@  .. cpp:var:: StatisticDuration cache_miss
     *\@\@
     *\@\@     The count of response cache misses and cumulative duration to lookup
     *\@\@     and insert output tensor data from the computed response to the
     * cache.
     *\@\@     For example, this duration should include the time to copy
     *\@\@     output tensor data from the response object to the Response Cache.
     *\@\@     Assuming the response cache is enabled for a given model, a cache
     *\@\@     miss occurs for a request to that model when the request metadata
     *\@\@     does NOT hash to an existing entry in the cache. See the response
     *\@\@     cache docs for more info:
     *\@\@
     * https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration cache_miss = 8;</code>
     */
    protected $cache_miss = null;

    /**
     * Constructor.
     *
     * @param array $data {
     *     Optional. Data for populating the Message object.
     *
     *     @type \Inference\StatisticDuration $success
     *          \@\@  .. cpp:var:: StatisticDuration success
     *          \@\@
     *          \@\@     Cumulative count and duration for successful inference
     *          \@\@     request. The "success" count and cumulative duration includes
     *          \@\@     cache hits.
     *          \@\@
     *     @type \Inference\StatisticDuration $fail
     *          \@\@  .. cpp:var:: StatisticDuration fail
     *          \@\@
     *          \@\@     Cumulative count and duration for failed inference
     *          \@\@     request.
     *          \@\@
     *     @type \Inference\StatisticDuration $queue
     *          \@\@  .. cpp:var:: StatisticDuration queue
     *          \@\@
     *          \@\@     The count and cumulative duration that inference requests wait in
     *          \@\@     scheduling or other queues. The "queue" count and cumulative
     *          \@\@     duration includes cache hits.
     *          \@\@
     *     @type \Inference\StatisticDuration $compute_input
     *          \@\@  .. cpp:var:: StatisticDuration compute_input
     *          \@\@
     *          \@\@     The count and cumulative duration to prepare input tensor data as
     *          \@\@     required by the model framework / backend. For example, this duration
     *          \@\@     should include the time to copy input tensor data to the GPU.
     *          \@\@     The "compute_input" count and cumulative duration do not account for
     *          \@\@     requests that were a cache hit. See the "cache_hit" field for more
     *          \@\@     info.
     *          \@\@
     *     @type \Inference\StatisticDuration $compute_infer
     *          \@\@  .. cpp:var:: StatisticDuration compute_infer
     *          \@\@
     *          \@\@     The count and cumulative duration to execute the model.
     *          \@\@     The "compute_infer" count and cumulative duration do not account for
     *          \@\@     requests that were a cache hit. See the "cache_hit" field for more
     *          \@\@     info.
     *          \@\@
     *     @type \Inference\StatisticDuration $compute_output
     *          \@\@  .. cpp:var:: StatisticDuration compute_output
     *          \@\@
     *          \@\@     The count and cumulative duration to extract output tensor data
     *          \@\@     produced by the model framework / backend. For example, this duration
     *          \@\@     should include the time to copy output tensor data from the GPU.
     *          \@\@     The "compute_output" count and cumulative duration do not account for
     *          \@\@     requests that were a cache hit. See the "cache_hit" field for more
     *          \@\@     info.
     *          \@\@
     *     @type \Inference\StatisticDuration $cache_hit
     *          \@\@  .. cpp:var:: StatisticDuration cache_hit
     *          \@\@
     *          \@\@     The count of response cache hits and cumulative duration to lookup
     *          \@\@     and extract output tensor data from the Response Cache on a cache
     *          \@\@     hit. For example, this duration should include the time to copy
     *          \@\@     output tensor data from the Response Cache to the response object.
     *          \@\@     On cache hits, triton does not need to go to the model/backend
     *          \@\@     for the output tensor data, so the "compute_input", "compute_infer",
     *          \@\@     and "compute_output" fields are not updated. Assuming the response
     *          \@\@     cache is enabled for a given model, a cache hit occurs for a
     *          \@\@     request to that model when the request metadata (model name,
     *          \@\@     model version, model inputs) hashes to an existing entry in the
     *          \@\@     cache. On a cache miss, the request hash and response output tensor
     *          \@\@     data is added to the cache. See response cache docs for more info:
     *          \@\@
     *           https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *          \@\@
     *     @type \Inference\StatisticDuration $cache_miss
     *          \@\@  .. cpp:var:: StatisticDuration cache_miss
     *          \@\@
     *          \@\@     The count of response cache misses and cumulative duration to lookup
     *          \@\@     and insert output tensor data from the computed response to the
     *           cache.
     *          \@\@     For example, this duration should include the time to copy
     *          \@\@     output tensor data from the response object to the Response Cache.
     *          \@\@     Assuming the response cache is enabled for a given model, a cache
     *          \@\@     miss occurs for a request to that model when the request metadata
     *          \@\@     does NOT hash to an existing entry in the cache. See the response
     *          \@\@     cache docs for more info:
     *          \@\@
     *           https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *          \@\@
     * }
     */
    public function __construct($data = NULL) {
        \GPBMetadata\GrpcService::initOnce();
        parent::__construct($data);
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration success
     *\@\@
     *\@\@     Cumulative count and duration for successful inference
     *\@\@     request. The "success" count and cumulative duration includes
     *\@\@     cache hits.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration success = 1;</code>
     * @return \Inference\StatisticDuration|null
     */
    public function getSuccess()
    {
        return $this->success;
    }

    public function hasSuccess()
    {
        return isset($this->success);
    }

    public function clearSuccess()
    {
        unset($this->success);
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration success
     *\@\@
     *\@\@     Cumulative count and duration for successful inference
     *\@\@     request. The "success" count and cumulative duration includes
     *\@\@     cache hits.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration success = 1;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setSuccess($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->success = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration fail
     *\@\@
     *\@\@     Cumulative count and duration for failed inference
     *\@\@     request.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration fail = 2;</code>
     * @return \Inference\StatisticDuration|null
     */
    public function getFail()
    {
        return $this->fail;
    }

    public function hasFail()
    {
        return isset($this->fail);
    }

    public function clearFail()
    {
        unset($this->fail);
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration fail
     *\@\@
     *\@\@     Cumulative count and duration for failed inference
     *\@\@     request.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration fail = 2;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setFail($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->fail = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration queue
     *\@\@
     *\@\@     The count and cumulative duration that inference requests wait in
     *\@\@     scheduling or other queues. The "queue" count and cumulative
     *\@\@     duration includes cache hits.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration queue = 3;</code>
     * @return \Inference\StatisticDuration|null
     */
    public function getQueue()
    {
        return $this->queue;
    }

    public function hasQueue()
    {
        return isset($this->queue);
    }

    public function clearQueue()
    {
        unset($this->queue);
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration queue
     *\@\@
     *\@\@     The count and cumulative duration that inference requests wait in
     *\@\@     scheduling or other queues. The "queue" count and cumulative
     *\@\@     duration includes cache hits.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration queue = 3;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setQueue($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->queue = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_input
     *\@\@
     *\@\@     The count and cumulative duration to prepare input tensor data as
     *\@\@     required by the model framework / backend. For example, this duration
     *\@\@     should include the time to copy input tensor data to the GPU.
     *\@\@     The "compute_input" count and cumulative duration do not account for
     *\@\@     requests that were a cache hit. See the "cache_hit" field for more
     *\@\@     info.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_input = 4;</code>
     * @return \Inference\StatisticDuration|null
     */
    public function getComputeInput()
    {
        return $this->compute_input;
    }

    public function hasComputeInput()
    {
        return isset($this->compute_input);
    }

    public function clearComputeInput()
    {
        unset($this->compute_input);
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_input
     *\@\@
     *\@\@     The count and cumulative duration to prepare input tensor data as
     *\@\@     required by the model framework / backend. For example, this duration
     *\@\@     should include the time to copy input tensor data to the GPU.
     *\@\@     The "compute_input" count and cumulative duration do not account for
     *\@\@     requests that were a cache hit. See the "cache_hit" field for more
     *\@\@     info.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_input = 4;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setComputeInput($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->compute_input = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_infer
     *\@\@
     *\@\@     The count and cumulative duration to execute the model.
     *\@\@     The "compute_infer" count and cumulative duration do not account for
     *\@\@     requests that were a cache hit. See the "cache_hit" field for more
     *\@\@     info.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_infer = 5;</code>
     * @return \Inference\StatisticDuration|null
     */
    public function getComputeInfer()
    {
        return $this->compute_infer;
    }

    public function hasComputeInfer()
    {
        return isset($this->compute_infer);
    }

    public function clearComputeInfer()
    {
        unset($this->compute_infer);
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_infer
     *\@\@
     *\@\@     The count and cumulative duration to execute the model.
     *\@\@     The "compute_infer" count and cumulative duration do not account for
     *\@\@     requests that were a cache hit. See the "cache_hit" field for more
     *\@\@     info.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_infer = 5;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setComputeInfer($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->compute_infer = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_output
     *\@\@
     *\@\@     The count and cumulative duration to extract output tensor data
     *\@\@     produced by the model framework / backend. For example, this duration
     *\@\@     should include the time to copy output tensor data from the GPU.
     *\@\@     The "compute_output" count and cumulative duration do not account for
     *\@\@     requests that were a cache hit. See the "cache_hit" field for more
     *\@\@     info.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_output = 6;</code>
     * @return \Inference\StatisticDuration|null
     */
    public function getComputeOutput()
    {
        return $this->compute_output;
    }

    public function hasComputeOutput()
    {
        return isset($this->compute_output);
    }

    public function clearComputeOutput()
    {
        unset($this->compute_output);
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration compute_output
     *\@\@
     *\@\@     The count and cumulative duration to extract output tensor data
     *\@\@     produced by the model framework / backend. For example, this duration
     *\@\@     should include the time to copy output tensor data from the GPU.
     *\@\@     The "compute_output" count and cumulative duration do not account for
     *\@\@     requests that were a cache hit. See the "cache_hit" field for more
     *\@\@     info.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_output = 6;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setComputeOutput($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->compute_output = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration cache_hit
     *\@\@
     *\@\@     The count of response cache hits and cumulative duration to lookup
     *\@\@     and extract output tensor data from the Response Cache on a cache
     *\@\@     hit. For example, this duration should include the time to copy
     *\@\@     output tensor data from the Response Cache to the response object.
     *\@\@     On cache hits, triton does not need to go to the model/backend
     *\@\@     for the output tensor data, so the "compute_input", "compute_infer",
     *\@\@     and "compute_output" fields are not updated. Assuming the response
     *\@\@     cache is enabled for a given model, a cache hit occurs for a
     *\@\@     request to that model when the request metadata (model name,
     *\@\@     model version, model inputs) hashes to an existing entry in the
     *\@\@     cache. On a cache miss, the request hash and response output tensor
     *\@\@     data is added to the cache. See response cache docs for more info:
     *\@\@
     * https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration cache_hit = 7;</code>
     * @return \Inference\StatisticDuration|null
     */
    public function getCacheHit()
    {
        return $this->cache_hit;
    }

    public function hasCacheHit()
    {
        return isset($this->cache_hit);
    }

    public function clearCacheHit()
    {
        unset($this->cache_hit);
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration cache_hit
     *\@\@
     *\@\@     The count of response cache hits and cumulative duration to lookup
     *\@\@     and extract output tensor data from the Response Cache on a cache
     *\@\@     hit. For example, this duration should include the time to copy
     *\@\@     output tensor data from the Response Cache to the response object.
     *\@\@     On cache hits, triton does not need to go to the model/backend
     *\@\@     for the output tensor data, so the "compute_input", "compute_infer",
     *\@\@     and "compute_output" fields are not updated. Assuming the response
     *\@\@     cache is enabled for a given model, a cache hit occurs for a
     *\@\@     request to that model when the request metadata (model name,
     *\@\@     model version, model inputs) hashes to an existing entry in the
     *\@\@     cache. On a cache miss, the request hash and response output tensor
     *\@\@     data is added to the cache. See response cache docs for more info:
     *\@\@
     * https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration cache_hit = 7;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setCacheHit($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->cache_hit = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration cache_miss
     *\@\@
     *\@\@     The count of response cache misses and cumulative duration to lookup
     *\@\@     and insert output tensor data from the computed response to the
     * cache.
     *\@\@     For example, this duration should include the time to copy
     *\@\@     output tensor data from the response object to the Response Cache.
     *\@\@     Assuming the response cache is enabled for a given model, a cache
     *\@\@     miss occurs for a request to that model when the request metadata
     *\@\@     does NOT hash to an existing entry in the cache. See the response
     *\@\@     cache docs for more info:
     *\@\@
     * https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration cache_miss = 8;</code>
     * @return \Inference\StatisticDuration|null
     */
    public function getCacheMiss()
    {
        return $this->cache_miss;
    }

    public function hasCacheMiss()
    {
        return isset($this->cache_miss);
    }

    public function clearCacheMiss()
    {
        unset($this->cache_miss);
    }

    /**
     *\@\@  .. cpp:var:: StatisticDuration cache_miss
     *\@\@
     *\@\@     The count of response cache misses and cumulative duration to lookup
     *\@\@     and insert output tensor data from the computed response to the
     * cache.
     *\@\@     For example, this duration should include the time to copy
     *\@\@     output tensor data from the response object to the Response Cache.
     *\@\@     Assuming the response cache is enabled for a given model, a cache
     *\@\@     miss occurs for a request to that model when the request metadata
     *\@\@     does NOT hash to an existing entry in the cache. See the response
     *\@\@     cache docs for more info:
     *\@\@
     * https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *\@\@
     *
     * Generated from protobuf field <code>.inference.StatisticDuration cache_miss = 8;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setCacheMiss($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->cache_miss = $var;

        return $this;
    }

}

