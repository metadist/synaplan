<?php
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: model_config.proto

namespace Inference;

use Google\Protobuf\Internal\GPBType;
use Google\Protobuf\Internal\GPBUtil;
use Google\Protobuf\RepeatedField;

/**
 *\@\@
 *\@\@.. cpp:var:: message ModelInstanceGroup
 *\@\@
 *\@\@   A group of one or more instances of a model and resources made
 *\@\@   available for those instances.
 *\@\@
 *
 * Generated from protobuf message <code>inference.ModelInstanceGroup</code>
 */
class ModelInstanceGroup extends \Google\Protobuf\Internal\Message
{
    /**
     *\@\@  .. cpp:var:: string name
     *\@\@
     *\@\@     Optional name of this group of instances. If not specified the
     *\@\@     name will be formed as <model name>_<group number>. The name of
     *\@\@     individual instances will be further formed by a unique instance
     *\@\@     number and GPU index:
     *\@\@
     *
     * Generated from protobuf field <code>string name = 1;</code>
     */
    protected $name = '';
    /**
     *\@\@  .. cpp:var:: Kind kind
     *\@\@
     *\@\@     The kind of this instance group. Default is KIND_AUTO. If
     *\@\@     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
     *\@\@     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
     *\@\@     and 'gpu' cannot be specified.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelInstanceGroup.Kind kind = 4;</code>
     */
    protected $kind = 0;
    /**
     *\@\@  .. cpp:var:: int32 count
     *\@\@
     *\@\@     For a group assigned to GPU, the number of instances created for
     *\@\@     each GPU listed in 'gpus'. For a group assigned to CPU the number
     *\@\@     of instances created. Default is 1.
     *
     * Generated from protobuf field <code>int32 count = 2;</code>
     */
    protected $count = 0;
    /**
     *\@\@  .. cpp:var:: ModelRateLimiter rate_limiter
     *\@\@
     *\@\@     The rate limiter specific settings to be associated with this
     *\@\@     instance group. Optional, if not specified no rate limiting
     *\@\@     will be applied to this instance group.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelRateLimiter rate_limiter = 6;</code>
     */
    protected $rate_limiter = null;
    /**
     *\@\@  .. cpp:var:: int32 gpus (repeated)
     *\@\@
     *\@\@     GPU(s) where instances should be available. For each GPU listed,
     *\@\@     'count' instances of the model will be available. Setting 'gpus'
     *\@\@     to empty (or not specifying at all) is equivalent to listing all
     *\@\@     available GPUs.
     *\@\@
     *
     * Generated from protobuf field <code>repeated int32 gpus = 3;</code>
     */
    private $gpus;
    /**
     *\@\@  .. cpp:var:: SecondaryDevice secondary_devices (repeated)
     *\@\@
     *\@\@     Secondary devices that are required by instances specified by this
     *\@\@     instance group. Optional.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelInstanceGroup.SecondaryDevice secondary_devices = 8;</code>
     */
    private $secondary_devices;
    /**
     *\@\@  .. cpp:var:: string profile (repeated)
     *\@\@
     *\@\@     For TensorRT models containing multiple optimization profile, this
     *\@\@     parameter specifies a set of optimization profiles available to this
     *\@\@     instance group. The inference server will choose the optimal profile
     *\@\@     based on the shapes of the input tensors. This field should lie
     *\@\@     between 0 and <TotalNumberOfOptimizationProfilesInPlanModel> - 1
     *\@\@     and be specified only for TensorRT backend, otherwise an error will
     *\@\@     be generated. If not specified, the server will select the first
     *\@\@     optimization profile by default.
     *\@\@
     *
     * Generated from protobuf field <code>repeated string profile = 5;</code>
     */
    private $profile;
    /**
     *\@\@  .. cpp:var:: bool passive
     *\@\@
     *\@\@     Whether the instances within this instance group will be accepting
     *\@\@     inference requests from the scheduler. If true, the instances will
     *\@\@     not be added to the scheduler. Default value is false.
     *\@\@
     *
     * Generated from protobuf field <code>bool passive = 7;</code>
     */
    protected $passive = false;
    /**
     *\@\@  .. cpp:var:: string host_policy
     *\@\@
     *\@\@     The host policy name that the instance to be associated with.
     *\@\@     The default value is set to reflect the device kind of the instance,
     *\@\@     for instance, KIND_CPU is "cpu", KIND_MODEL is "model" and
     *\@\@     KIND_GPU is "gpu_<gpu_id>".
     *\@\@
     *
     * Generated from protobuf field <code>string host_policy = 9;</code>
     */
    protected $host_policy = '';

    /**
     * Constructor.
     *
     * @param array $data {
     *     Optional. Data for populating the Message object.
     *
     *     @type string $name
     *          \@\@  .. cpp:var:: string name
     *          \@\@
     *          \@\@     Optional name of this group of instances. If not specified the
     *          \@\@     name will be formed as <model name>_<group number>. The name of
     *          \@\@     individual instances will be further formed by a unique instance
     *          \@\@     number and GPU index:
     *          \@\@
     *     @type int $kind
     *          \@\@  .. cpp:var:: Kind kind
     *          \@\@
     *          \@\@     The kind of this instance group. Default is KIND_AUTO. If
     *          \@\@     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
     *          \@\@     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
     *          \@\@     and 'gpu' cannot be specified.
     *          \@\@
     *     @type int $count
     *          \@\@  .. cpp:var:: int32 count
     *          \@\@
     *          \@\@     For a group assigned to GPU, the number of instances created for
     *          \@\@     each GPU listed in 'gpus'. For a group assigned to CPU the number
     *          \@\@     of instances created. Default is 1.
     *     @type \Inference\ModelRateLimiter $rate_limiter
     *          \@\@  .. cpp:var:: ModelRateLimiter rate_limiter
     *          \@\@
     *          \@\@     The rate limiter specific settings to be associated with this
     *          \@\@     instance group. Optional, if not specified no rate limiting
     *          \@\@     will be applied to this instance group.
     *          \@\@
     *     @type int[] $gpus
     *          \@\@  .. cpp:var:: int32 gpus (repeated)
     *          \@\@
     *          \@\@     GPU(s) where instances should be available. For each GPU listed,
     *          \@\@     'count' instances of the model will be available. Setting 'gpus'
     *          \@\@     to empty (or not specifying at all) is equivalent to listing all
     *          \@\@     available GPUs.
     *          \@\@
     *     @type \Inference\ModelInstanceGroup\SecondaryDevice[] $secondary_devices
     *          \@\@  .. cpp:var:: SecondaryDevice secondary_devices (repeated)
     *          \@\@
     *          \@\@     Secondary devices that are required by instances specified by this
     *          \@\@     instance group. Optional.
     *          \@\@
     *     @type string[] $profile
     *          \@\@  .. cpp:var:: string profile (repeated)
     *          \@\@
     *          \@\@     For TensorRT models containing multiple optimization profile, this
     *          \@\@     parameter specifies a set of optimization profiles available to this
     *          \@\@     instance group. The inference server will choose the optimal profile
     *          \@\@     based on the shapes of the input tensors. This field should lie
     *          \@\@     between 0 and <TotalNumberOfOptimizationProfilesInPlanModel> - 1
     *          \@\@     and be specified only for TensorRT backend, otherwise an error will
     *          \@\@     be generated. If not specified, the server will select the first
     *          \@\@     optimization profile by default.
     *          \@\@
     *     @type bool $passive
     *          \@\@  .. cpp:var:: bool passive
     *          \@\@
     *          \@\@     Whether the instances within this instance group will be accepting
     *          \@\@     inference requests from the scheduler. If true, the instances will
     *          \@\@     not be added to the scheduler. Default value is false.
     *          \@\@
     *     @type string $host_policy
     *          \@\@  .. cpp:var:: string host_policy
     *          \@\@
     *          \@\@     The host policy name that the instance to be associated with.
     *          \@\@     The default value is set to reflect the device kind of the instance,
     *          \@\@     for instance, KIND_CPU is "cpu", KIND_MODEL is "model" and
     *          \@\@     KIND_GPU is "gpu_<gpu_id>".
     *          \@\@
     * }
     */
    public function __construct($data = NULL) {
        \GPBMetadata\ModelConfig::initOnce();
        parent::__construct($data);
    }

    /**
     *\@\@  .. cpp:var:: string name
     *\@\@
     *\@\@     Optional name of this group of instances. If not specified the
     *\@\@     name will be formed as <model name>_<group number>. The name of
     *\@\@     individual instances will be further formed by a unique instance
     *\@\@     number and GPU index:
     *\@\@
     *
     * Generated from protobuf field <code>string name = 1;</code>
     * @return string
     */
    public function getName()
    {
        return $this->name;
    }

    /**
     *\@\@  .. cpp:var:: string name
     *\@\@
     *\@\@     Optional name of this group of instances. If not specified the
     *\@\@     name will be formed as <model name>_<group number>. The name of
     *\@\@     individual instances will be further formed by a unique instance
     *\@\@     number and GPU index:
     *\@\@
     *
     * Generated from protobuf field <code>string name = 1;</code>
     * @param string $var
     * @return $this
     */
    public function setName($var)
    {
        GPBUtil::checkString($var, True);
        $this->name = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: Kind kind
     *\@\@
     *\@\@     The kind of this instance group. Default is KIND_AUTO. If
     *\@\@     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
     *\@\@     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
     *\@\@     and 'gpu' cannot be specified.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelInstanceGroup.Kind kind = 4;</code>
     * @return int
     */
    public function getKind()
    {
        return $this->kind;
    }

    /**
     *\@\@  .. cpp:var:: Kind kind
     *\@\@
     *\@\@     The kind of this instance group. Default is KIND_AUTO. If
     *\@\@     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
     *\@\@     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
     *\@\@     and 'gpu' cannot be specified.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelInstanceGroup.Kind kind = 4;</code>
     * @param int $var
     * @return $this
     */
    public function setKind($var)
    {
        GPBUtil::checkEnum($var, \Inference\ModelInstanceGroup\Kind::class);
        $this->kind = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: int32 count
     *\@\@
     *\@\@     For a group assigned to GPU, the number of instances created for
     *\@\@     each GPU listed in 'gpus'. For a group assigned to CPU the number
     *\@\@     of instances created. Default is 1.
     *
     * Generated from protobuf field <code>int32 count = 2;</code>
     * @return int
     */
    public function getCount()
    {
        return $this->count;
    }

    /**
     *\@\@  .. cpp:var:: int32 count
     *\@\@
     *\@\@     For a group assigned to GPU, the number of instances created for
     *\@\@     each GPU listed in 'gpus'. For a group assigned to CPU the number
     *\@\@     of instances created. Default is 1.
     *
     * Generated from protobuf field <code>int32 count = 2;</code>
     * @param int $var
     * @return $this
     */
    public function setCount($var)
    {
        GPBUtil::checkInt32($var);
        $this->count = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: ModelRateLimiter rate_limiter
     *\@\@
     *\@\@     The rate limiter specific settings to be associated with this
     *\@\@     instance group. Optional, if not specified no rate limiting
     *\@\@     will be applied to this instance group.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelRateLimiter rate_limiter = 6;</code>
     * @return \Inference\ModelRateLimiter|null
     */
    public function getRateLimiter()
    {
        return $this->rate_limiter;
    }

    public function hasRateLimiter()
    {
        return isset($this->rate_limiter);
    }

    public function clearRateLimiter()
    {
        unset($this->rate_limiter);
    }

    /**
     *\@\@  .. cpp:var:: ModelRateLimiter rate_limiter
     *\@\@
     *\@\@     The rate limiter specific settings to be associated with this
     *\@\@     instance group. Optional, if not specified no rate limiting
     *\@\@     will be applied to this instance group.
     *\@\@
     *
     * Generated from protobuf field <code>.inference.ModelRateLimiter rate_limiter = 6;</code>
     * @param \Inference\ModelRateLimiter $var
     * @return $this
     */
    public function setRateLimiter($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelRateLimiter::class);
        $this->rate_limiter = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: int32 gpus (repeated)
     *\@\@
     *\@\@     GPU(s) where instances should be available. For each GPU listed,
     *\@\@     'count' instances of the model will be available. Setting 'gpus'
     *\@\@     to empty (or not specifying at all) is equivalent to listing all
     *\@\@     available GPUs.
     *\@\@
     *
     * Generated from protobuf field <code>repeated int32 gpus = 3;</code>
     * @return RepeatedField<int>
     */
    public function getGpus()
    {
        return $this->gpus;
    }

    /**
     *\@\@  .. cpp:var:: int32 gpus (repeated)
     *\@\@
     *\@\@     GPU(s) where instances should be available. For each GPU listed,
     *\@\@     'count' instances of the model will be available. Setting 'gpus'
     *\@\@     to empty (or not specifying at all) is equivalent to listing all
     *\@\@     available GPUs.
     *\@\@
     *
     * Generated from protobuf field <code>repeated int32 gpus = 3;</code>
     * @param int[] $var
     * @return $this
     */
    public function setGpus($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::INT32);
        $this->gpus = $arr;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: SecondaryDevice secondary_devices (repeated)
     *\@\@
     *\@\@     Secondary devices that are required by instances specified by this
     *\@\@     instance group. Optional.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelInstanceGroup.SecondaryDevice secondary_devices = 8;</code>
     * @return RepeatedField<\Inference\ModelInstanceGroup\SecondaryDevice>
     */
    public function getSecondaryDevices()
    {
        return $this->secondary_devices;
    }

    /**
     *\@\@  .. cpp:var:: SecondaryDevice secondary_devices (repeated)
     *\@\@
     *\@\@     Secondary devices that are required by instances specified by this
     *\@\@     instance group. Optional.
     *\@\@
     *
     * Generated from protobuf field <code>repeated .inference.ModelInstanceGroup.SecondaryDevice secondary_devices = 8;</code>
     * @param \Inference\ModelInstanceGroup\SecondaryDevice[] $var
     * @return $this
     */
    public function setSecondaryDevices($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\ModelInstanceGroup\SecondaryDevice::class);
        $this->secondary_devices = $arr;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: string profile (repeated)
     *\@\@
     *\@\@     For TensorRT models containing multiple optimization profile, this
     *\@\@     parameter specifies a set of optimization profiles available to this
     *\@\@     instance group. The inference server will choose the optimal profile
     *\@\@     based on the shapes of the input tensors. This field should lie
     *\@\@     between 0 and <TotalNumberOfOptimizationProfilesInPlanModel> - 1
     *\@\@     and be specified only for TensorRT backend, otherwise an error will
     *\@\@     be generated. If not specified, the server will select the first
     *\@\@     optimization profile by default.
     *\@\@
     *
     * Generated from protobuf field <code>repeated string profile = 5;</code>
     * @return RepeatedField<string>
     */
    public function getProfile()
    {
        return $this->profile;
    }

    /**
     *\@\@  .. cpp:var:: string profile (repeated)
     *\@\@
     *\@\@     For TensorRT models containing multiple optimization profile, this
     *\@\@     parameter specifies a set of optimization profiles available to this
     *\@\@     instance group. The inference server will choose the optimal profile
     *\@\@     based on the shapes of the input tensors. This field should lie
     *\@\@     between 0 and <TotalNumberOfOptimizationProfilesInPlanModel> - 1
     *\@\@     and be specified only for TensorRT backend, otherwise an error will
     *\@\@     be generated. If not specified, the server will select the first
     *\@\@     optimization profile by default.
     *\@\@
     *
     * Generated from protobuf field <code>repeated string profile = 5;</code>
     * @param string[] $var
     * @return $this
     */
    public function setProfile($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::STRING);
        $this->profile = $arr;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: bool passive
     *\@\@
     *\@\@     Whether the instances within this instance group will be accepting
     *\@\@     inference requests from the scheduler. If true, the instances will
     *\@\@     not be added to the scheduler. Default value is false.
     *\@\@
     *
     * Generated from protobuf field <code>bool passive = 7;</code>
     * @return bool
     */
    public function getPassive()
    {
        return $this->passive;
    }

    /**
     *\@\@  .. cpp:var:: bool passive
     *\@\@
     *\@\@     Whether the instances within this instance group will be accepting
     *\@\@     inference requests from the scheduler. If true, the instances will
     *\@\@     not be added to the scheduler. Default value is false.
     *\@\@
     *
     * Generated from protobuf field <code>bool passive = 7;</code>
     * @param bool $var
     * @return $this
     */
    public function setPassive($var)
    {
        GPBUtil::checkBool($var);
        $this->passive = $var;

        return $this;
    }

    /**
     *\@\@  .. cpp:var:: string host_policy
     *\@\@
     *\@\@     The host policy name that the instance to be associated with.
     *\@\@     The default value is set to reflect the device kind of the instance,
     *\@\@     for instance, KIND_CPU is "cpu", KIND_MODEL is "model" and
     *\@\@     KIND_GPU is "gpu_<gpu_id>".
     *\@\@
     *
     * Generated from protobuf field <code>string host_policy = 9;</code>
     * @return string
     */
    public function getHostPolicy()
    {
        return $this->host_policy;
    }

    /**
     *\@\@  .. cpp:var:: string host_policy
     *\@\@
     *\@\@     The host policy name that the instance to be associated with.
     *\@\@     The default value is set to reflect the device kind of the instance,
     *\@\@     for instance, KIND_CPU is "cpu", KIND_MODEL is "model" and
     *\@\@     KIND_GPU is "gpu_<gpu_id>".
     *\@\@
     *
     * Generated from protobuf field <code>string host_policy = 9;</code>
     * @param string $var
     * @return $this
     */
    public function setHostPolicy($var)
    {
        GPBUtil::checkString($var, True);
        $this->host_policy = $var;

        return $this;
    }

}

