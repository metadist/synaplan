<?php
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: model_config.proto

namespace Inference;

use Google\Protobuf\Internal\GPBType;
use Google\Protobuf\Internal\RepeatedField;
use Google\Protobuf\Internal\GPBUtil;

/**
 *&#64;&#64;
 *&#64;&#64;.. cpp:var:: message ModelConfig
 *&#64;&#64;
 *&#64;&#64;   A model configuration.
 *&#64;&#64;
 *
 * Generated from protobuf message <code>inference.ModelConfig</code>
 */
class ModelConfig extends \Google\Protobuf\Internal\Message
{
    /**
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string name = 1;</code>
     */
    protected $name = '';
    /**
     *&#64;&#64;  .. cpp:var:: string platform
     *&#64;&#64;
     *&#64;&#64;     Additional backend-specific configuration for the model.
     *&#64;&#64;     Please refer to the backend documentation on whether this field
     *&#64;&#64;     should be specified.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string platform = 2;</code>
     */
    protected $platform = '';
    /**
     *&#64;&#64;  .. cpp:var:: string backend
     *&#64;&#64;
     *&#64;&#64;     The backend used by the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string backend = 17;</code>
     */
    protected $backend = '';
    /**
     *&#64;&#64;  .. cpp:var:: string runtime
     *&#64;&#64;
     *&#64;&#64;     The name of the backend library file used by the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string runtime = 25;</code>
     */
    protected $runtime = '';
    /**
     *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
     *&#64;&#64;
     *&#64;&#64;     Policy indicating which version(s) of the model will be served.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelVersionPolicy version_policy = 3;</code>
     */
    protected $version_policy = null;
    /**
     *&#64;&#64;  .. cpp:var:: int32 max_batch_size
     *&#64;&#64;
     *&#64;&#64;     Maximum batch size allowed for inference. This can only decrease
     *&#64;&#64;     what is allowed by the model itself. A max_batch_size value of 0
     *&#64;&#64;     indicates that batching is not allowed for the model and the
     *&#64;&#64;     dimension/shape of the input and output tensors must exactly
     *&#64;&#64;     match what is specified in the input and output configuration. A
     *&#64;&#64;     max_batch_size value > 0 indicates that batching is allowed and
     *&#64;&#64;     so the model expects the input tensors to have an additional
     *&#64;&#64;     initial dimension for the batching that is not specified in the
     *&#64;&#64;     input (for example, if the model supports batched inputs of
     *&#64;&#64;     2-dimensional tensors then the model configuration will specify
     *&#64;&#64;     the input shape as [ X, Y ] but the model will expect the actual
     *&#64;&#64;     input tensors to have shape [ N, X, Y ]). For max_batch_size > 0
     *&#64;&#64;     returned outputs will also have an additional initial dimension
     *&#64;&#64;     for the batch.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>int32 max_batch_size = 4;</code>
     */
    protected $max_batch_size = 0;
    /**
     *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The inputs request by the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelInput input = 5;</code>
     */
    private $input;
    /**
     *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelOutput output = 6;</code>
     */
    private $output;
    /**
     *&#64;&#64;  .. cpp:var:: BatchInput batch_input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The model input(s) that the server should use to communicate
     *&#64;&#64;     batch related values to the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.BatchInput batch_input = 20;</code>
     */
    private $batch_input;
    /**
     *&#64;&#64;  .. cpp:var:: BatchOutput batch_output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model that requires special handling
     *&#64;&#64;     by the model backend.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.BatchOutput batch_output = 21;</code>
     */
    private $batch_output;
    /**
     *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
     *&#64;&#64;
     *&#64;&#64;     Optimization configuration for the model. If not specified
     *&#64;&#64;     then default optimization policy is used.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelOptimizationPolicy optimization = 12;</code>
     */
    protected $optimization = null;
    /**
     *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *&#64;&#64;
     *&#64;&#64;     Instances of this model. If not specified, one instance
     *&#64;&#64;     of the model will be instantiated on each available GPU.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     */
    private $instance_group;
    /**
     *&#64;&#64;  .. cpp:var:: string default_model_filename
     *&#64;&#64;
     *&#64;&#64;     Optional filename of the model file to use if a
     *&#64;&#64;     compute-capability specific model is not specified in
     *&#64;&#64;     :cpp:var:`cc_model_filenames`. If not specified the default name
     *&#64;&#64;     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
     *&#64;&#64;     'model.pt' depending on the model type.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string default_model_filename = 8;</code>
     */
    protected $default_model_filename = '';
    /**
     *&#64;&#64;  .. cpp:var:: map<string,string> cc_model_filenames
     *&#64;&#64;
     *&#64;&#64;     Optional map from CUDA compute capability to the filename of
     *&#64;&#64;     the model that supports that compute capability. The filename
     *&#64;&#64;     refers to a file within the model version directory.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>map<string, string> cc_model_filenames = 9;</code>
     */
    private $cc_model_filenames;
    /**
     *&#64;&#64;  .. cpp:var:: map<string,string> metric_tags
     *&#64;&#64;
     *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
     *&#64;&#64;     reported for this model. These tags are applied to the metrics
     *&#64;&#64;     reported on the HTTP metrics port.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>map<string, string> metric_tags = 10;</code>
     */
    private $metric_tags;
    /**
     *&#64;&#64;  .. cpp:var:: map<string,ModelParameter> parameters
     *&#64;&#64;
     *&#64;&#64;     Optional model parameters. User-specified parameter values.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>map<string, .inference.ModelParameter> parameters = 14;</code>
     */
    private $parameters;
    /**
     *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *&#64;&#64;
     *&#64;&#64;     Warmup setting of this model. If specified, all instances
     *&#64;&#64;     will be run with the request samples in sequence before
     *&#64;&#64;     serving the model.
     *&#64;&#64;     This field can only be specified if the model is not an ensemble
     *&#64;&#64;     model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     */
    private $model_warmup;
    /**
     *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
     *&#64;&#64;
     *&#64;&#64;     Optional metadata of the libraries providing custom operations for
     *&#64;&#64;     this model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelOperations model_operations = 18;</code>
     */
    protected $model_operations = null;
    /**
     *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *&#64;&#64;
     *&#64;&#64;     Optional specification that describes the nature of transactions
     *&#64;&#64;     to be expected from the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
     */
    protected $model_transaction_policy = null;
    /**
     *&#64;&#64;  .. cpp:var:: ModelRepositoryAgents model_repository_agents
     *&#64;&#64;
     *&#64;&#64;     Optional specification of the agent(s) that should be invoked
     *&#64;&#64;     with repository actions are performed for this model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelRepositoryAgents model_repository_agents = 23;</code>
     */
    protected $model_repository_agents = null;
    /**
     *&#64;&#64;  .. cpp:var:: ModelResponseCache response_cache
     *&#64;&#64;
     *&#64;&#64;     Optional setting for utilizing the response cache for this
     *&#64;&#64;     model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelResponseCache response_cache = 24;</code>
     */
    protected $response_cache = null;
    /**
     *&#64;&#64;  .. cpp:var:: ModelMetrics model_metrics
     *&#64;&#64;
     *&#64;&#64;     Optional setting for custom metrics configuration for this model.
     *&#64;&#64;     Application default is applied to metrics that are not specified.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelMetrics model_metrics = 26;</code>
     */
    protected $model_metrics = null;
    protected $scheduling_choice;

    /**
     * Constructor.
     *
     * @param array $data {
     *     Optional. Data for populating the Message object.
     *
     *     @type string $name
     *          &#64;&#64;  .. cpp:var:: string name
     *          &#64;&#64;
     *          &#64;&#64;     The name of the model.
     *          &#64;&#64;
     *     @type string $platform
     *          &#64;&#64;  .. cpp:var:: string platform
     *          &#64;&#64;
     *          &#64;&#64;     Additional backend-specific configuration for the model.
     *          &#64;&#64;     Please refer to the backend documentation on whether this field
     *          &#64;&#64;     should be specified.
     *          &#64;&#64;
     *     @type string $backend
     *          &#64;&#64;  .. cpp:var:: string backend
     *          &#64;&#64;
     *          &#64;&#64;     The backend used by the model.
     *          &#64;&#64;
     *     @type string $runtime
     *          &#64;&#64;  .. cpp:var:: string runtime
     *          &#64;&#64;
     *          &#64;&#64;     The name of the backend library file used by the model.
     *          &#64;&#64;
     *     @type \Inference\ModelVersionPolicy $version_policy
     *          &#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
     *          &#64;&#64;
     *          &#64;&#64;     Policy indicating which version(s) of the model will be served.
     *          &#64;&#64;
     *     @type int $max_batch_size
     *          &#64;&#64;  .. cpp:var:: int32 max_batch_size
     *          &#64;&#64;
     *          &#64;&#64;     Maximum batch size allowed for inference. This can only decrease
     *          &#64;&#64;     what is allowed by the model itself. A max_batch_size value of 0
     *          &#64;&#64;     indicates that batching is not allowed for the model and the
     *          &#64;&#64;     dimension/shape of the input and output tensors must exactly
     *          &#64;&#64;     match what is specified in the input and output configuration. A
     *          &#64;&#64;     max_batch_size value > 0 indicates that batching is allowed and
     *          &#64;&#64;     so the model expects the input tensors to have an additional
     *          &#64;&#64;     initial dimension for the batching that is not specified in the
     *          &#64;&#64;     input (for example, if the model supports batched inputs of
     *          &#64;&#64;     2-dimensional tensors then the model configuration will specify
     *          &#64;&#64;     the input shape as [ X, Y ] but the model will expect the actual
     *          &#64;&#64;     input tensors to have shape [ N, X, Y ]). For max_batch_size > 0
     *          &#64;&#64;     returned outputs will also have an additional initial dimension
     *          &#64;&#64;     for the batch.
     *          &#64;&#64;
     *     @type \Inference\ModelInput[]|\Google\Protobuf\Internal\RepeatedField $input
     *          &#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *          &#64;&#64;
     *          &#64;&#64;     The inputs request by the model.
     *          &#64;&#64;
     *     @type \Inference\ModelOutput[]|\Google\Protobuf\Internal\RepeatedField $output
     *          &#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *          &#64;&#64;
     *          &#64;&#64;     The outputs produced by the model.
     *          &#64;&#64;
     *     @type \Inference\BatchInput[]|\Google\Protobuf\Internal\RepeatedField $batch_input
     *          &#64;&#64;  .. cpp:var:: BatchInput batch_input (repeated)
     *          &#64;&#64;
     *          &#64;&#64;     The model input(s) that the server should use to communicate
     *          &#64;&#64;     batch related values to the model.
     *          &#64;&#64;
     *     @type \Inference\BatchOutput[]|\Google\Protobuf\Internal\RepeatedField $batch_output
     *          &#64;&#64;  .. cpp:var:: BatchOutput batch_output (repeated)
     *          &#64;&#64;
     *          &#64;&#64;     The outputs produced by the model that requires special handling
     *          &#64;&#64;     by the model backend.
     *          &#64;&#64;
     *     @type \Inference\ModelOptimizationPolicy $optimization
     *          &#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
     *          &#64;&#64;
     *          &#64;&#64;     Optimization configuration for the model. If not specified
     *          &#64;&#64;     then default optimization policy is used.
     *          &#64;&#64;
     *     @type \Inference\ModelDynamicBatching $dynamic_batching
     *          &#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
     *          &#64;&#64;
     *          &#64;&#64;       If specified, enables the dynamic-batching scheduling
     *          &#64;&#64;       policy. With dynamic-batching the scheduler may group
     *          &#64;&#64;       together independent requests into a single batch to
     *          &#64;&#64;       improve inference throughput.
     *          &#64;&#64;
     *     @type \Inference\ModelSequenceBatching $sequence_batching
     *          &#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
     *          &#64;&#64;
     *          &#64;&#64;       If specified, enables the sequence-batching scheduling
     *          &#64;&#64;       policy. With sequence-batching, inference requests
     *          &#64;&#64;       with the same correlation ID are routed to the same
     *          &#64;&#64;       model instance. Multiple sequences of inference requests
     *          &#64;&#64;       may be batched together into a single batch to
     *          &#64;&#64;       improve inference throughput.
     *          &#64;&#64;
     *     @type \Inference\ModelEnsembling $ensemble_scheduling
     *          &#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
     *          &#64;&#64;
     *          &#64;&#64;       If specified, enables the model-ensembling scheduling
     *          &#64;&#64;       policy. With model-ensembling, inference requests
     *          &#64;&#64;       will be processed according to the specification, such as an
     *          &#64;&#64;       execution sequence of models. The input specified in this model
     *          &#64;&#64;       config will be the input for the ensemble, and the output
     *          &#64;&#64;       specified will be the output of the ensemble.
     *          &#64;&#64;
     *     @type \Inference\ModelInstanceGroup[]|\Google\Protobuf\Internal\RepeatedField $instance_group
     *          &#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *          &#64;&#64;
     *          &#64;&#64;     Instances of this model. If not specified, one instance
     *          &#64;&#64;     of the model will be instantiated on each available GPU.
     *          &#64;&#64;
     *     @type string $default_model_filename
     *          &#64;&#64;  .. cpp:var:: string default_model_filename
     *          &#64;&#64;
     *          &#64;&#64;     Optional filename of the model file to use if a
     *          &#64;&#64;     compute-capability specific model is not specified in
     *          &#64;&#64;     :cpp:var:`cc_model_filenames`. If not specified the default name
     *          &#64;&#64;     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
     *          &#64;&#64;     'model.pt' depending on the model type.
     *          &#64;&#64;
     *     @type array|\Google\Protobuf\Internal\MapField $cc_model_filenames
     *          &#64;&#64;  .. cpp:var:: map<string,string> cc_model_filenames
     *          &#64;&#64;
     *          &#64;&#64;     Optional map from CUDA compute capability to the filename of
     *          &#64;&#64;     the model that supports that compute capability. The filename
     *          &#64;&#64;     refers to a file within the model version directory.
     *          &#64;&#64;
     *     @type array|\Google\Protobuf\Internal\MapField $metric_tags
     *          &#64;&#64;  .. cpp:var:: map<string,string> metric_tags
     *          &#64;&#64;
     *          &#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
     *          &#64;&#64;     reported for this model. These tags are applied to the metrics
     *          &#64;&#64;     reported on the HTTP metrics port.
     *          &#64;&#64;
     *     @type array|\Google\Protobuf\Internal\MapField $parameters
     *          &#64;&#64;  .. cpp:var:: map<string,ModelParameter> parameters
     *          &#64;&#64;
     *          &#64;&#64;     Optional model parameters. User-specified parameter values.
     *          &#64;&#64;
     *     @type \Inference\ModelWarmup[]|\Google\Protobuf\Internal\RepeatedField $model_warmup
     *          &#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *          &#64;&#64;
     *          &#64;&#64;     Warmup setting of this model. If specified, all instances
     *          &#64;&#64;     will be run with the request samples in sequence before
     *          &#64;&#64;     serving the model.
     *          &#64;&#64;     This field can only be specified if the model is not an ensemble
     *          &#64;&#64;     model.
     *          &#64;&#64;
     *     @type \Inference\ModelOperations $model_operations
     *          &#64;&#64;  .. cpp:var:: ModelOperations model_operations
     *          &#64;&#64;
     *          &#64;&#64;     Optional metadata of the libraries providing custom operations for
     *          &#64;&#64;     this model.
     *          &#64;&#64;
     *     @type \Inference\ModelTransactionPolicy $model_transaction_policy
     *          &#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *          &#64;&#64;
     *          &#64;&#64;     Optional specification that describes the nature of transactions
     *          &#64;&#64;     to be expected from the model.
     *          &#64;&#64;
     *     @type \Inference\ModelRepositoryAgents $model_repository_agents
     *          &#64;&#64;  .. cpp:var:: ModelRepositoryAgents model_repository_agents
     *          &#64;&#64;
     *          &#64;&#64;     Optional specification of the agent(s) that should be invoked
     *          &#64;&#64;     with repository actions are performed for this model.
     *          &#64;&#64;
     *     @type \Inference\ModelResponseCache $response_cache
     *          &#64;&#64;  .. cpp:var:: ModelResponseCache response_cache
     *          &#64;&#64;
     *          &#64;&#64;     Optional setting for utilizing the response cache for this
     *          &#64;&#64;     model.
     *          &#64;&#64;
     *     @type \Inference\ModelMetrics $model_metrics
     *          &#64;&#64;  .. cpp:var:: ModelMetrics model_metrics
     *          &#64;&#64;
     *          &#64;&#64;     Optional setting for custom metrics configuration for this model.
     *          &#64;&#64;     Application default is applied to metrics that are not specified.
     *          &#64;&#64;
     * }
     */
    public function __construct($data = NULL) {
        \GPBMetadata\ModelConfig::initOnce();
        parent::__construct($data);
    }

    /**
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string name = 1;</code>
     * @return string
     */
    public function getName()
    {
        return $this->name;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string name = 1;</code>
     * @param string $var
     * @return $this
     */
    public function setName($var)
    {
        GPBUtil::checkString($var, True);
        $this->name = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string platform
     *&#64;&#64;
     *&#64;&#64;     Additional backend-specific configuration for the model.
     *&#64;&#64;     Please refer to the backend documentation on whether this field
     *&#64;&#64;     should be specified.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string platform = 2;</code>
     * @return string
     */
    public function getPlatform()
    {
        return $this->platform;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string platform
     *&#64;&#64;
     *&#64;&#64;     Additional backend-specific configuration for the model.
     *&#64;&#64;     Please refer to the backend documentation on whether this field
     *&#64;&#64;     should be specified.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string platform = 2;</code>
     * @param string $var
     * @return $this
     */
    public function setPlatform($var)
    {
        GPBUtil::checkString($var, True);
        $this->platform = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string backend
     *&#64;&#64;
     *&#64;&#64;     The backend used by the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string backend = 17;</code>
     * @return string
     */
    public function getBackend()
    {
        return $this->backend;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string backend
     *&#64;&#64;
     *&#64;&#64;     The backend used by the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string backend = 17;</code>
     * @param string $var
     * @return $this
     */
    public function setBackend($var)
    {
        GPBUtil::checkString($var, True);
        $this->backend = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string runtime
     *&#64;&#64;
     *&#64;&#64;     The name of the backend library file used by the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string runtime = 25;</code>
     * @return string
     */
    public function getRuntime()
    {
        return $this->runtime;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string runtime
     *&#64;&#64;
     *&#64;&#64;     The name of the backend library file used by the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string runtime = 25;</code>
     * @param string $var
     * @return $this
     */
    public function setRuntime($var)
    {
        GPBUtil::checkString($var, True);
        $this->runtime = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
     *&#64;&#64;
     *&#64;&#64;     Policy indicating which version(s) of the model will be served.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelVersionPolicy version_policy = 3;</code>
     * @return \Inference\ModelVersionPolicy
     */
    public function getVersionPolicy()
    {
        return $this->version_policy;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
     *&#64;&#64;
     *&#64;&#64;     Policy indicating which version(s) of the model will be served.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelVersionPolicy version_policy = 3;</code>
     * @param \Inference\ModelVersionPolicy $var
     * @return $this
     */
    public function setVersionPolicy($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelVersionPolicy::class);
        $this->version_policy = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: int32 max_batch_size
     *&#64;&#64;
     *&#64;&#64;     Maximum batch size allowed for inference. This can only decrease
     *&#64;&#64;     what is allowed by the model itself. A max_batch_size value of 0
     *&#64;&#64;     indicates that batching is not allowed for the model and the
     *&#64;&#64;     dimension/shape of the input and output tensors must exactly
     *&#64;&#64;     match what is specified in the input and output configuration. A
     *&#64;&#64;     max_batch_size value > 0 indicates that batching is allowed and
     *&#64;&#64;     so the model expects the input tensors to have an additional
     *&#64;&#64;     initial dimension for the batching that is not specified in the
     *&#64;&#64;     input (for example, if the model supports batched inputs of
     *&#64;&#64;     2-dimensional tensors then the model configuration will specify
     *&#64;&#64;     the input shape as [ X, Y ] but the model will expect the actual
     *&#64;&#64;     input tensors to have shape [ N, X, Y ]). For max_batch_size > 0
     *&#64;&#64;     returned outputs will also have an additional initial dimension
     *&#64;&#64;     for the batch.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>int32 max_batch_size = 4;</code>
     * @return int
     */
    public function getMaxBatchSize()
    {
        return $this->max_batch_size;
    }

    /**
     *&#64;&#64;  .. cpp:var:: int32 max_batch_size
     *&#64;&#64;
     *&#64;&#64;     Maximum batch size allowed for inference. This can only decrease
     *&#64;&#64;     what is allowed by the model itself. A max_batch_size value of 0
     *&#64;&#64;     indicates that batching is not allowed for the model and the
     *&#64;&#64;     dimension/shape of the input and output tensors must exactly
     *&#64;&#64;     match what is specified in the input and output configuration. A
     *&#64;&#64;     max_batch_size value > 0 indicates that batching is allowed and
     *&#64;&#64;     so the model expects the input tensors to have an additional
     *&#64;&#64;     initial dimension for the batching that is not specified in the
     *&#64;&#64;     input (for example, if the model supports batched inputs of
     *&#64;&#64;     2-dimensional tensors then the model configuration will specify
     *&#64;&#64;     the input shape as [ X, Y ] but the model will expect the actual
     *&#64;&#64;     input tensors to have shape [ N, X, Y ]). For max_batch_size > 0
     *&#64;&#64;     returned outputs will also have an additional initial dimension
     *&#64;&#64;     for the batch.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>int32 max_batch_size = 4;</code>
     * @param int $var
     * @return $this
     */
    public function setMaxBatchSize($var)
    {
        GPBUtil::checkInt32($var);
        $this->max_batch_size = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The inputs request by the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelInput input = 5;</code>
     * @return \Google\Protobuf\Internal\RepeatedField
     */
    public function getInput()
    {
        return $this->input;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The inputs request by the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelInput input = 5;</code>
     * @param \Inference\ModelInput[]|\Google\Protobuf\Internal\RepeatedField $var
     * @return $this
     */
    public function setInput($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\ModelInput::class);
        $this->input = $arr;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelOutput output = 6;</code>
     * @return \Google\Protobuf\Internal\RepeatedField
     */
    public function getOutput()
    {
        return $this->output;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelOutput output = 6;</code>
     * @param \Inference\ModelOutput[]|\Google\Protobuf\Internal\RepeatedField $var
     * @return $this
     */
    public function setOutput($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\ModelOutput::class);
        $this->output = $arr;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: BatchInput batch_input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The model input(s) that the server should use to communicate
     *&#64;&#64;     batch related values to the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.BatchInput batch_input = 20;</code>
     * @return \Google\Protobuf\Internal\RepeatedField
     */
    public function getBatchInput()
    {
        return $this->batch_input;
    }

    /**
     *&#64;&#64;  .. cpp:var:: BatchInput batch_input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The model input(s) that the server should use to communicate
     *&#64;&#64;     batch related values to the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.BatchInput batch_input = 20;</code>
     * @param \Inference\BatchInput[]|\Google\Protobuf\Internal\RepeatedField $var
     * @return $this
     */
    public function setBatchInput($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\BatchInput::class);
        $this->batch_input = $arr;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: BatchOutput batch_output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model that requires special handling
     *&#64;&#64;     by the model backend.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.BatchOutput batch_output = 21;</code>
     * @return \Google\Protobuf\Internal\RepeatedField
     */
    public function getBatchOutput()
    {
        return $this->batch_output;
    }

    /**
     *&#64;&#64;  .. cpp:var:: BatchOutput batch_output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model that requires special handling
     *&#64;&#64;     by the model backend.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.BatchOutput batch_output = 21;</code>
     * @param \Inference\BatchOutput[]|\Google\Protobuf\Internal\RepeatedField $var
     * @return $this
     */
    public function setBatchOutput($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\BatchOutput::class);
        $this->batch_output = $arr;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
     *&#64;&#64;
     *&#64;&#64;     Optimization configuration for the model. If not specified
     *&#64;&#64;     then default optimization policy is used.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelOptimizationPolicy optimization = 12;</code>
     * @return \Inference\ModelOptimizationPolicy
     */
    public function getOptimization()
    {
        return $this->optimization;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
     *&#64;&#64;
     *&#64;&#64;     Optimization configuration for the model. If not specified
     *&#64;&#64;     then default optimization policy is used.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelOptimizationPolicy optimization = 12;</code>
     * @param \Inference\ModelOptimizationPolicy $var
     * @return $this
     */
    public function setOptimization($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelOptimizationPolicy::class);
        $this->optimization = $var;

        return $this;
    }

    /**
     *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the dynamic-batching scheduling
     *&#64;&#64;       policy. With dynamic-batching the scheduler may group
     *&#64;&#64;       together independent requests into a single batch to
     *&#64;&#64;       improve inference throughput.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelDynamicBatching dynamic_batching = 11;</code>
     * @return \Inference\ModelDynamicBatching
     */
    public function getDynamicBatching()
    {
        return $this->readOneof(11);
    }

    /**
     *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the dynamic-batching scheduling
     *&#64;&#64;       policy. With dynamic-batching the scheduler may group
     *&#64;&#64;       together independent requests into a single batch to
     *&#64;&#64;       improve inference throughput.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelDynamicBatching dynamic_batching = 11;</code>
     * @param \Inference\ModelDynamicBatching $var
     * @return $this
     */
    public function setDynamicBatching($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelDynamicBatching::class);
        $this->writeOneof(11, $var);

        return $this;
    }

    /**
     *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the sequence-batching scheduling
     *&#64;&#64;       policy. With sequence-batching, inference requests
     *&#64;&#64;       with the same correlation ID are routed to the same
     *&#64;&#64;       model instance. Multiple sequences of inference requests
     *&#64;&#64;       may be batched together into a single batch to
     *&#64;&#64;       improve inference throughput.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelSequenceBatching sequence_batching = 13;</code>
     * @return \Inference\ModelSequenceBatching
     */
    public function getSequenceBatching()
    {
        return $this->readOneof(13);
    }

    /**
     *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the sequence-batching scheduling
     *&#64;&#64;       policy. With sequence-batching, inference requests
     *&#64;&#64;       with the same correlation ID are routed to the same
     *&#64;&#64;       model instance. Multiple sequences of inference requests
     *&#64;&#64;       may be batched together into a single batch to
     *&#64;&#64;       improve inference throughput.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelSequenceBatching sequence_batching = 13;</code>
     * @param \Inference\ModelSequenceBatching $var
     * @return $this
     */
    public function setSequenceBatching($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelSequenceBatching::class);
        $this->writeOneof(13, $var);

        return $this;
    }

    /**
     *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the model-ensembling scheduling
     *&#64;&#64;       policy. With model-ensembling, inference requests
     *&#64;&#64;       will be processed according to the specification, such as an
     *&#64;&#64;       execution sequence of models. The input specified in this model
     *&#64;&#64;       config will be the input for the ensemble, and the output
     *&#64;&#64;       specified will be the output of the ensemble.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelEnsembling ensemble_scheduling = 15;</code>
     * @return \Inference\ModelEnsembling
     */
    public function getEnsembleScheduling()
    {
        return $this->readOneof(15);
    }

    /**
     *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the model-ensembling scheduling
     *&#64;&#64;       policy. With model-ensembling, inference requests
     *&#64;&#64;       will be processed according to the specification, such as an
     *&#64;&#64;       execution sequence of models. The input specified in this model
     *&#64;&#64;       config will be the input for the ensemble, and the output
     *&#64;&#64;       specified will be the output of the ensemble.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelEnsembling ensemble_scheduling = 15;</code>
     * @param \Inference\ModelEnsembling $var
     * @return $this
     */
    public function setEnsembleScheduling($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelEnsembling::class);
        $this->writeOneof(15, $var);

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *&#64;&#64;
     *&#64;&#64;     Instances of this model. If not specified, one instance
     *&#64;&#64;     of the model will be instantiated on each available GPU.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     * @return \Google\Protobuf\Internal\RepeatedField
     */
    public function getInstanceGroup()
    {
        return $this->instance_group;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *&#64;&#64;
     *&#64;&#64;     Instances of this model. If not specified, one instance
     *&#64;&#64;     of the model will be instantiated on each available GPU.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     * @param \Inference\ModelInstanceGroup[]|\Google\Protobuf\Internal\RepeatedField $var
     * @return $this
     */
    public function setInstanceGroup($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\ModelInstanceGroup::class);
        $this->instance_group = $arr;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string default_model_filename
     *&#64;&#64;
     *&#64;&#64;     Optional filename of the model file to use if a
     *&#64;&#64;     compute-capability specific model is not specified in
     *&#64;&#64;     :cpp:var:`cc_model_filenames`. If not specified the default name
     *&#64;&#64;     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
     *&#64;&#64;     'model.pt' depending on the model type.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string default_model_filename = 8;</code>
     * @return string
     */
    public function getDefaultModelFilename()
    {
        return $this->default_model_filename;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string default_model_filename
     *&#64;&#64;
     *&#64;&#64;     Optional filename of the model file to use if a
     *&#64;&#64;     compute-capability specific model is not specified in
     *&#64;&#64;     :cpp:var:`cc_model_filenames`. If not specified the default name
     *&#64;&#64;     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
     *&#64;&#64;     'model.pt' depending on the model type.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string default_model_filename = 8;</code>
     * @param string $var
     * @return $this
     */
    public function setDefaultModelFilename($var)
    {
        GPBUtil::checkString($var, True);
        $this->default_model_filename = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: map<string,string> cc_model_filenames
     *&#64;&#64;
     *&#64;&#64;     Optional map from CUDA compute capability to the filename of
     *&#64;&#64;     the model that supports that compute capability. The filename
     *&#64;&#64;     refers to a file within the model version directory.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>map<string, string> cc_model_filenames = 9;</code>
     * @return \Google\Protobuf\Internal\MapField
     */
    public function getCcModelFilenames()
    {
        return $this->cc_model_filenames;
    }

    /**
     *&#64;&#64;  .. cpp:var:: map<string,string> cc_model_filenames
     *&#64;&#64;
     *&#64;&#64;     Optional map from CUDA compute capability to the filename of
     *&#64;&#64;     the model that supports that compute capability. The filename
     *&#64;&#64;     refers to a file within the model version directory.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>map<string, string> cc_model_filenames = 9;</code>
     * @param array|\Google\Protobuf\Internal\MapField $var
     * @return $this
     */
    public function setCcModelFilenames($var)
    {
        $arr = GPBUtil::checkMapField($var, \Google\Protobuf\Internal\GPBType::STRING, \Google\Protobuf\Internal\GPBType::STRING);
        $this->cc_model_filenames = $arr;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: map<string,string> metric_tags
     *&#64;&#64;
     *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
     *&#64;&#64;     reported for this model. These tags are applied to the metrics
     *&#64;&#64;     reported on the HTTP metrics port.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>map<string, string> metric_tags = 10;</code>
     * @return \Google\Protobuf\Internal\MapField
     */
    public function getMetricTags()
    {
        return $this->metric_tags;
    }

    /**
     *&#64;&#64;  .. cpp:var:: map<string,string> metric_tags
     *&#64;&#64;
     *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
     *&#64;&#64;     reported for this model. These tags are applied to the metrics
     *&#64;&#64;     reported on the HTTP metrics port.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>map<string, string> metric_tags = 10;</code>
     * @param array|\Google\Protobuf\Internal\MapField $var
     * @return $this
     */
    public function setMetricTags($var)
    {
        $arr = GPBUtil::checkMapField($var, \Google\Protobuf\Internal\GPBType::STRING, \Google\Protobuf\Internal\GPBType::STRING);
        $this->metric_tags = $arr;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: map<string,ModelParameter> parameters
     *&#64;&#64;
     *&#64;&#64;     Optional model parameters. User-specified parameter values.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>map<string, .inference.ModelParameter> parameters = 14;</code>
     * @return \Google\Protobuf\Internal\MapField
     */
    public function getParameters()
    {
        return $this->parameters;
    }

    /**
     *&#64;&#64;  .. cpp:var:: map<string,ModelParameter> parameters
     *&#64;&#64;
     *&#64;&#64;     Optional model parameters. User-specified parameter values.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>map<string, .inference.ModelParameter> parameters = 14;</code>
     * @param array|\Google\Protobuf\Internal\MapField $var
     * @return $this
     */
    public function setParameters($var)
    {
        $arr = GPBUtil::checkMapField($var, \Google\Protobuf\Internal\GPBType::STRING, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\ModelParameter::class);
        $this->parameters = $arr;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *&#64;&#64;
     *&#64;&#64;     Warmup setting of this model. If specified, all instances
     *&#64;&#64;     will be run with the request samples in sequence before
     *&#64;&#64;     serving the model.
     *&#64;&#64;     This field can only be specified if the model is not an ensemble
     *&#64;&#64;     model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     * @return \Google\Protobuf\Internal\RepeatedField
     */
    public function getModelWarmup()
    {
        return $this->model_warmup;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *&#64;&#64;
     *&#64;&#64;     Warmup setting of this model. If specified, all instances
     *&#64;&#64;     will be run with the request samples in sequence before
     *&#64;&#64;     serving the model.
     *&#64;&#64;     This field can only be specified if the model is not an ensemble
     *&#64;&#64;     model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     * @param \Inference\ModelWarmup[]|\Google\Protobuf\Internal\RepeatedField $var
     * @return $this
     */
    public function setModelWarmup($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\ModelWarmup::class);
        $this->model_warmup = $arr;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
     *&#64;&#64;
     *&#64;&#64;     Optional metadata of the libraries providing custom operations for
     *&#64;&#64;     this model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelOperations model_operations = 18;</code>
     * @return \Inference\ModelOperations
     */
    public function getModelOperations()
    {
        return $this->model_operations;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
     *&#64;&#64;
     *&#64;&#64;     Optional metadata of the libraries providing custom operations for
     *&#64;&#64;     this model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelOperations model_operations = 18;</code>
     * @param \Inference\ModelOperations $var
     * @return $this
     */
    public function setModelOperations($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelOperations::class);
        $this->model_operations = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *&#64;&#64;
     *&#64;&#64;     Optional specification that describes the nature of transactions
     *&#64;&#64;     to be expected from the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
     * @return \Inference\ModelTransactionPolicy
     */
    public function getModelTransactionPolicy()
    {
        return $this->model_transaction_policy;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *&#64;&#64;
     *&#64;&#64;     Optional specification that describes the nature of transactions
     *&#64;&#64;     to be expected from the model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
     * @param \Inference\ModelTransactionPolicy $var
     * @return $this
     */
    public function setModelTransactionPolicy($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelTransactionPolicy::class);
        $this->model_transaction_policy = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelRepositoryAgents model_repository_agents
     *&#64;&#64;
     *&#64;&#64;     Optional specification of the agent(s) that should be invoked
     *&#64;&#64;     with repository actions are performed for this model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelRepositoryAgents model_repository_agents = 23;</code>
     * @return \Inference\ModelRepositoryAgents
     */
    public function getModelRepositoryAgents()
    {
        return $this->model_repository_agents;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelRepositoryAgents model_repository_agents
     *&#64;&#64;
     *&#64;&#64;     Optional specification of the agent(s) that should be invoked
     *&#64;&#64;     with repository actions are performed for this model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelRepositoryAgents model_repository_agents = 23;</code>
     * @param \Inference\ModelRepositoryAgents $var
     * @return $this
     */
    public function setModelRepositoryAgents($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelRepositoryAgents::class);
        $this->model_repository_agents = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelResponseCache response_cache
     *&#64;&#64;
     *&#64;&#64;     Optional setting for utilizing the response cache for this
     *&#64;&#64;     model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelResponseCache response_cache = 24;</code>
     * @return \Inference\ModelResponseCache
     */
    public function getResponseCache()
    {
        return $this->response_cache;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelResponseCache response_cache
     *&#64;&#64;
     *&#64;&#64;     Optional setting for utilizing the response cache for this
     *&#64;&#64;     model.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelResponseCache response_cache = 24;</code>
     * @param \Inference\ModelResponseCache $var
     * @return $this
     */
    public function setResponseCache($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelResponseCache::class);
        $this->response_cache = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelMetrics model_metrics
     *&#64;&#64;
     *&#64;&#64;     Optional setting for custom metrics configuration for this model.
     *&#64;&#64;     Application default is applied to metrics that are not specified.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelMetrics model_metrics = 26;</code>
     * @return \Inference\ModelMetrics
     */
    public function getModelMetrics()
    {
        return $this->model_metrics;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelMetrics model_metrics
     *&#64;&#64;
     *&#64;&#64;     Optional setting for custom metrics configuration for this model.
     *&#64;&#64;     Application default is applied to metrics that are not specified.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelMetrics model_metrics = 26;</code>
     * @param \Inference\ModelMetrics $var
     * @return $this
     */
    public function setModelMetrics($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelMetrics::class);
        $this->model_metrics = $var;

        return $this;
    }

    /**
     * @return string
     */
    public function getSchedulingChoice()
    {
        return $this->whichOneof("scheduling_choice");
    }

}

