<?php
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: model_config.proto

namespace Inference;

use Google\Protobuf\Internal\GPBType;
use Google\Protobuf\Internal\RepeatedField;
use Google\Protobuf\Internal\GPBUtil;

/**
 *&#64;&#64;
 *&#64;&#64;.. cpp:var:: message ModelInstanceGroup
 *&#64;&#64;
 *&#64;&#64;   A group of one or more instances of a model and resources made
 *&#64;&#64;   available for those instances.
 *&#64;&#64;
 *
 * Generated from protobuf message <code>inference.ModelInstanceGroup</code>
 */
class ModelInstanceGroup extends \Google\Protobuf\Internal\Message
{
    /**
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     Optional name of this group of instances. If not specified the
     *&#64;&#64;     name will be formed as <model name>_<group number>. The name of
     *&#64;&#64;     individual instances will be further formed by a unique instance
     *&#64;&#64;     number and GPU index:
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string name = 1;</code>
     */
    protected $name = '';
    /**
     *&#64;&#64;  .. cpp:var:: Kind kind
     *&#64;&#64;
     *&#64;&#64;     The kind of this instance group. Default is KIND_AUTO. If
     *&#64;&#64;     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
     *&#64;&#64;     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
     *&#64;&#64;     and 'gpu' cannot be specified.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelInstanceGroup.Kind kind = 4;</code>
     */
    protected $kind = 0;
    /**
     *&#64;&#64;  .. cpp:var:: int32 count
     *&#64;&#64;
     *&#64;&#64;     For a group assigned to GPU, the number of instances created for
     *&#64;&#64;     each GPU listed in 'gpus'. For a group assigned to CPU the number
     *&#64;&#64;     of instances created. Default is 1.
     *
     * Generated from protobuf field <code>int32 count = 2;</code>
     */
    protected $count = 0;
    /**
     *&#64;&#64;  .. cpp:var:: ModelRateLimiter rate_limiter
     *&#64;&#64;
     *&#64;&#64;     The rate limiter specific settings to be associated with this
     *&#64;&#64;     instance group. Optional, if not specified no rate limiting
     *&#64;&#64;     will be applied to this instance group.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelRateLimiter rate_limiter = 6;</code>
     */
    protected $rate_limiter = null;
    /**
     *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
     *&#64;&#64;
     *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
     *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
     *&#64;&#64;     to empty (or not specifying at all) is equivalent to listing all
     *&#64;&#64;     available GPUs.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated int32 gpus = 3;</code>
     */
    private $gpus;
    /**
     *&#64;&#64;  .. cpp:var:: SecondaryDevice secondary_devices (repeated)
     *&#64;&#64;
     *&#64;&#64;     Secondary devices that are required by instances specified by this
     *&#64;&#64;     instance group. Optional.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelInstanceGroup.SecondaryDevice secondary_devices = 8;</code>
     */
    private $secondary_devices;
    /**
     *&#64;&#64;  .. cpp:var:: string profile (repeated)
     *&#64;&#64;
     *&#64;&#64;     For TensorRT models containing multiple optimization profile, this
     *&#64;&#64;     parameter specifies a set of optimization profiles available to this
     *&#64;&#64;     instance group. The inference server will choose the optimal profile
     *&#64;&#64;     based on the shapes of the input tensors. This field should lie
     *&#64;&#64;     between 0 and <TotalNumberOfOptimizationProfilesInPlanModel> - 1
     *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
     *&#64;&#64;     be generated. If not specified, the server will select the first
     *&#64;&#64;     optimization profile by default.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated string profile = 5;</code>
     */
    private $profile;
    /**
     *&#64;&#64;  .. cpp:var:: bool passive
     *&#64;&#64;
     *&#64;&#64;     Whether the instances within this instance group will be accepting
     *&#64;&#64;     inference requests from the scheduler. If true, the instances will
     *&#64;&#64;     not be added to the scheduler. Default value is false.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>bool passive = 7;</code>
     */
    protected $passive = false;
    /**
     *&#64;&#64;  .. cpp:var:: string host_policy
     *&#64;&#64;
     *&#64;&#64;     The host policy name that the instance to be associated with.
     *&#64;&#64;     The default value is set to reflect the device kind of the instance,
     *&#64;&#64;     for instance, KIND_CPU is "cpu", KIND_MODEL is "model" and
     *&#64;&#64;     KIND_GPU is "gpu_<gpu_id>".
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string host_policy = 9;</code>
     */
    protected $host_policy = '';

    /**
     * Constructor.
     *
     * @param array $data {
     *     Optional. Data for populating the Message object.
     *
     *     @type string $name
     *          &#64;&#64;  .. cpp:var:: string name
     *          &#64;&#64;
     *          &#64;&#64;     Optional name of this group of instances. If not specified the
     *          &#64;&#64;     name will be formed as <model name>_<group number>. The name of
     *          &#64;&#64;     individual instances will be further formed by a unique instance
     *          &#64;&#64;     number and GPU index:
     *          &#64;&#64;
     *     @type int $kind
     *          &#64;&#64;  .. cpp:var:: Kind kind
     *          &#64;&#64;
     *          &#64;&#64;     The kind of this instance group. Default is KIND_AUTO. If
     *          &#64;&#64;     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
     *          &#64;&#64;     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
     *          &#64;&#64;     and 'gpu' cannot be specified.
     *          &#64;&#64;
     *     @type int $count
     *          &#64;&#64;  .. cpp:var:: int32 count
     *          &#64;&#64;
     *          &#64;&#64;     For a group assigned to GPU, the number of instances created for
     *          &#64;&#64;     each GPU listed in 'gpus'. For a group assigned to CPU the number
     *          &#64;&#64;     of instances created. Default is 1.
     *     @type \Inference\ModelRateLimiter $rate_limiter
     *          &#64;&#64;  .. cpp:var:: ModelRateLimiter rate_limiter
     *          &#64;&#64;
     *          &#64;&#64;     The rate limiter specific settings to be associated with this
     *          &#64;&#64;     instance group. Optional, if not specified no rate limiting
     *          &#64;&#64;     will be applied to this instance group.
     *          &#64;&#64;
     *     @type int[]|\Google\Protobuf\Internal\RepeatedField $gpus
     *          &#64;&#64;  .. cpp:var:: int32 gpus (repeated)
     *          &#64;&#64;
     *          &#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
     *          &#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
     *          &#64;&#64;     to empty (or not specifying at all) is equivalent to listing all
     *          &#64;&#64;     available GPUs.
     *          &#64;&#64;
     *     @type \Inference\ModelInstanceGroup\SecondaryDevice[]|\Google\Protobuf\Internal\RepeatedField $secondary_devices
     *          &#64;&#64;  .. cpp:var:: SecondaryDevice secondary_devices (repeated)
     *          &#64;&#64;
     *          &#64;&#64;     Secondary devices that are required by instances specified by this
     *          &#64;&#64;     instance group. Optional.
     *          &#64;&#64;
     *     @type string[]|\Google\Protobuf\Internal\RepeatedField $profile
     *          &#64;&#64;  .. cpp:var:: string profile (repeated)
     *          &#64;&#64;
     *          &#64;&#64;     For TensorRT models containing multiple optimization profile, this
     *          &#64;&#64;     parameter specifies a set of optimization profiles available to this
     *          &#64;&#64;     instance group. The inference server will choose the optimal profile
     *          &#64;&#64;     based on the shapes of the input tensors. This field should lie
     *          &#64;&#64;     between 0 and <TotalNumberOfOptimizationProfilesInPlanModel> - 1
     *          &#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
     *          &#64;&#64;     be generated. If not specified, the server will select the first
     *          &#64;&#64;     optimization profile by default.
     *          &#64;&#64;
     *     @type bool $passive
     *          &#64;&#64;  .. cpp:var:: bool passive
     *          &#64;&#64;
     *          &#64;&#64;     Whether the instances within this instance group will be accepting
     *          &#64;&#64;     inference requests from the scheduler. If true, the instances will
     *          &#64;&#64;     not be added to the scheduler. Default value is false.
     *          &#64;&#64;
     *     @type string $host_policy
     *          &#64;&#64;  .. cpp:var:: string host_policy
     *          &#64;&#64;
     *          &#64;&#64;     The host policy name that the instance to be associated with.
     *          &#64;&#64;     The default value is set to reflect the device kind of the instance,
     *          &#64;&#64;     for instance, KIND_CPU is "cpu", KIND_MODEL is "model" and
     *          &#64;&#64;     KIND_GPU is "gpu_<gpu_id>".
     *          &#64;&#64;
     * }
     */
    public function __construct($data = NULL) {
        \GPBMetadata\ModelConfig::initOnce();
        parent::__construct($data);
    }

    /**
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     Optional name of this group of instances. If not specified the
     *&#64;&#64;     name will be formed as <model name>_<group number>. The name of
     *&#64;&#64;     individual instances will be further formed by a unique instance
     *&#64;&#64;     number and GPU index:
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string name = 1;</code>
     * @return string
     */
    public function getName()
    {
        return $this->name;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     Optional name of this group of instances. If not specified the
     *&#64;&#64;     name will be formed as <model name>_<group number>. The name of
     *&#64;&#64;     individual instances will be further formed by a unique instance
     *&#64;&#64;     number and GPU index:
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string name = 1;</code>
     * @param string $var
     * @return $this
     */
    public function setName($var)
    {
        GPBUtil::checkString($var, True);
        $this->name = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: Kind kind
     *&#64;&#64;
     *&#64;&#64;     The kind of this instance group. Default is KIND_AUTO. If
     *&#64;&#64;     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
     *&#64;&#64;     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
     *&#64;&#64;     and 'gpu' cannot be specified.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelInstanceGroup.Kind kind = 4;</code>
     * @return int
     */
    public function getKind()
    {
        return $this->kind;
    }

    /**
     *&#64;&#64;  .. cpp:var:: Kind kind
     *&#64;&#64;
     *&#64;&#64;     The kind of this instance group. Default is KIND_AUTO. If
     *&#64;&#64;     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
     *&#64;&#64;     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
     *&#64;&#64;     and 'gpu' cannot be specified.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelInstanceGroup.Kind kind = 4;</code>
     * @param int $var
     * @return $this
     */
    public function setKind($var)
    {
        GPBUtil::checkEnum($var, \Inference\ModelInstanceGroup_Kind::class);
        $this->kind = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: int32 count
     *&#64;&#64;
     *&#64;&#64;     For a group assigned to GPU, the number of instances created for
     *&#64;&#64;     each GPU listed in 'gpus'. For a group assigned to CPU the number
     *&#64;&#64;     of instances created. Default is 1.
     *
     * Generated from protobuf field <code>int32 count = 2;</code>
     * @return int
     */
    public function getCount()
    {
        return $this->count;
    }

    /**
     *&#64;&#64;  .. cpp:var:: int32 count
     *&#64;&#64;
     *&#64;&#64;     For a group assigned to GPU, the number of instances created for
     *&#64;&#64;     each GPU listed in 'gpus'. For a group assigned to CPU the number
     *&#64;&#64;     of instances created. Default is 1.
     *
     * Generated from protobuf field <code>int32 count = 2;</code>
     * @param int $var
     * @return $this
     */
    public function setCount($var)
    {
        GPBUtil::checkInt32($var);
        $this->count = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelRateLimiter rate_limiter
     *&#64;&#64;
     *&#64;&#64;     The rate limiter specific settings to be associated with this
     *&#64;&#64;     instance group. Optional, if not specified no rate limiting
     *&#64;&#64;     will be applied to this instance group.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelRateLimiter rate_limiter = 6;</code>
     * @return \Inference\ModelRateLimiter
     */
    public function getRateLimiter()
    {
        return $this->rate_limiter;
    }

    /**
     *&#64;&#64;  .. cpp:var:: ModelRateLimiter rate_limiter
     *&#64;&#64;
     *&#64;&#64;     The rate limiter specific settings to be associated with this
     *&#64;&#64;     instance group. Optional, if not specified no rate limiting
     *&#64;&#64;     will be applied to this instance group.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.ModelRateLimiter rate_limiter = 6;</code>
     * @param \Inference\ModelRateLimiter $var
     * @return $this
     */
    public function setRateLimiter($var)
    {
        GPBUtil::checkMessage($var, \Inference\ModelRateLimiter::class);
        $this->rate_limiter = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
     *&#64;&#64;
     *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
     *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
     *&#64;&#64;     to empty (or not specifying at all) is equivalent to listing all
     *&#64;&#64;     available GPUs.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated int32 gpus = 3;</code>
     * @return \Google\Protobuf\Internal\RepeatedField
     */
    public function getGpus()
    {
        return $this->gpus;
    }

    /**
     *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
     *&#64;&#64;
     *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
     *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
     *&#64;&#64;     to empty (or not specifying at all) is equivalent to listing all
     *&#64;&#64;     available GPUs.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated int32 gpus = 3;</code>
     * @param int[]|\Google\Protobuf\Internal\RepeatedField $var
     * @return $this
     */
    public function setGpus($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::INT32);
        $this->gpus = $arr;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: SecondaryDevice secondary_devices (repeated)
     *&#64;&#64;
     *&#64;&#64;     Secondary devices that are required by instances specified by this
     *&#64;&#64;     instance group. Optional.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelInstanceGroup.SecondaryDevice secondary_devices = 8;</code>
     * @return \Google\Protobuf\Internal\RepeatedField
     */
    public function getSecondaryDevices()
    {
        return $this->secondary_devices;
    }

    /**
     *&#64;&#64;  .. cpp:var:: SecondaryDevice secondary_devices (repeated)
     *&#64;&#64;
     *&#64;&#64;     Secondary devices that are required by instances specified by this
     *&#64;&#64;     instance group. Optional.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated .inference.ModelInstanceGroup.SecondaryDevice secondary_devices = 8;</code>
     * @param \Inference\ModelInstanceGroup\SecondaryDevice[]|\Google\Protobuf\Internal\RepeatedField $var
     * @return $this
     */
    public function setSecondaryDevices($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::MESSAGE, \Inference\ModelInstanceGroup\SecondaryDevice::class);
        $this->secondary_devices = $arr;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string profile (repeated)
     *&#64;&#64;
     *&#64;&#64;     For TensorRT models containing multiple optimization profile, this
     *&#64;&#64;     parameter specifies a set of optimization profiles available to this
     *&#64;&#64;     instance group. The inference server will choose the optimal profile
     *&#64;&#64;     based on the shapes of the input tensors. This field should lie
     *&#64;&#64;     between 0 and <TotalNumberOfOptimizationProfilesInPlanModel> - 1
     *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
     *&#64;&#64;     be generated. If not specified, the server will select the first
     *&#64;&#64;     optimization profile by default.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated string profile = 5;</code>
     * @return \Google\Protobuf\Internal\RepeatedField
     */
    public function getProfile()
    {
        return $this->profile;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string profile (repeated)
     *&#64;&#64;
     *&#64;&#64;     For TensorRT models containing multiple optimization profile, this
     *&#64;&#64;     parameter specifies a set of optimization profiles available to this
     *&#64;&#64;     instance group. The inference server will choose the optimal profile
     *&#64;&#64;     based on the shapes of the input tensors. This field should lie
     *&#64;&#64;     between 0 and <TotalNumberOfOptimizationProfilesInPlanModel> - 1
     *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
     *&#64;&#64;     be generated. If not specified, the server will select the first
     *&#64;&#64;     optimization profile by default.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>repeated string profile = 5;</code>
     * @param string[]|\Google\Protobuf\Internal\RepeatedField $var
     * @return $this
     */
    public function setProfile($var)
    {
        $arr = GPBUtil::checkRepeatedField($var, \Google\Protobuf\Internal\GPBType::STRING);
        $this->profile = $arr;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: bool passive
     *&#64;&#64;
     *&#64;&#64;     Whether the instances within this instance group will be accepting
     *&#64;&#64;     inference requests from the scheduler. If true, the instances will
     *&#64;&#64;     not be added to the scheduler. Default value is false.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>bool passive = 7;</code>
     * @return bool
     */
    public function getPassive()
    {
        return $this->passive;
    }

    /**
     *&#64;&#64;  .. cpp:var:: bool passive
     *&#64;&#64;
     *&#64;&#64;     Whether the instances within this instance group will be accepting
     *&#64;&#64;     inference requests from the scheduler. If true, the instances will
     *&#64;&#64;     not be added to the scheduler. Default value is false.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>bool passive = 7;</code>
     * @param bool $var
     * @return $this
     */
    public function setPassive($var)
    {
        GPBUtil::checkBool($var);
        $this->passive = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string host_policy
     *&#64;&#64;
     *&#64;&#64;     The host policy name that the instance to be associated with.
     *&#64;&#64;     The default value is set to reflect the device kind of the instance,
     *&#64;&#64;     for instance, KIND_CPU is "cpu", KIND_MODEL is "model" and
     *&#64;&#64;     KIND_GPU is "gpu_<gpu_id>".
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string host_policy = 9;</code>
     * @return string
     */
    public function getHostPolicy()
    {
        return $this->host_policy;
    }

    /**
     *&#64;&#64;  .. cpp:var:: string host_policy
     *&#64;&#64;
     *&#64;&#64;     The host policy name that the instance to be associated with.
     *&#64;&#64;     The default value is set to reflect the device kind of the instance,
     *&#64;&#64;     for instance, KIND_CPU is "cpu", KIND_MODEL is "model" and
     *&#64;&#64;     KIND_GPU is "gpu_<gpu_id>".
     *&#64;&#64;
     *
     * Generated from protobuf field <code>string host_policy = 9;</code>
     * @param string $var
     * @return $this
     */
    public function setHostPolicy($var)
    {
        GPBUtil::checkString($var, True);
        $this->host_policy = $var;

        return $this;
    }

}

