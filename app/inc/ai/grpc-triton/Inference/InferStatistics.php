<?php
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: grpc_service.proto

namespace Inference;

use Google\Protobuf\Internal\GPBType;
use Google\Protobuf\Internal\RepeatedField;
use Google\Protobuf\Internal\GPBUtil;

/**
 *&#64;&#64;
 *&#64;&#64;.. cpp:var:: message InferStatistics
 *&#64;&#64;
 *&#64;&#64;   Inference statistics.
 *&#64;&#64;
 *
 * Generated from protobuf message <code>inference.InferStatistics</code>
 */
class InferStatistics extends \Google\Protobuf\Internal\Message
{
    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration success
     *&#64;&#64;
     *&#64;&#64;     Cumulative count and duration for successful inference
     *&#64;&#64;     request. The "success" count and cumulative duration includes
     *&#64;&#64;     cache hits.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration success = 1;</code>
     */
    protected $success = null;
    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration fail
     *&#64;&#64;
     *&#64;&#64;     Cumulative count and duration for failed inference
     *&#64;&#64;     request.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration fail = 2;</code>
     */
    protected $fail = null;
    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration queue
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration that inference requests wait in
     *&#64;&#64;     scheduling or other queues. The "queue" count and cumulative
     *&#64;&#64;     duration includes cache hits.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration queue = 3;</code>
     */
    protected $queue = null;
    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_input
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to prepare input tensor data as
     *&#64;&#64;     required by the model framework / backend. For example, this duration
     *&#64;&#64;     should include the time to copy input tensor data to the GPU.
     *&#64;&#64;     The "compute_input" count and cumulative duration do not account for
     *&#64;&#64;     requests that were a cache hit. See the "cache_hit" field for more
     *&#64;&#64;     info.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_input = 4;</code>
     */
    protected $compute_input = null;
    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_infer
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to execute the model.
     *&#64;&#64;     The "compute_infer" count and cumulative duration do not account for
     *&#64;&#64;     requests that were a cache hit. See the "cache_hit" field for more
     *&#64;&#64;     info.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_infer = 5;</code>
     */
    protected $compute_infer = null;
    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_output
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to extract output tensor data
     *&#64;&#64;     produced by the model framework / backend. For example, this duration
     *&#64;&#64;     should include the time to copy output tensor data from the GPU.
     *&#64;&#64;     The "compute_output" count and cumulative duration do not account for
     *&#64;&#64;     requests that were a cache hit. See the "cache_hit" field for more
     *&#64;&#64;     info.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_output = 6;</code>
     */
    protected $compute_output = null;
    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration cache_hit
     *&#64;&#64;
     *&#64;&#64;     The count of response cache hits and cumulative duration to lookup
     *&#64;&#64;     and extract output tensor data from the Response Cache on a cache
     *&#64;&#64;     hit. For example, this duration should include the time to copy
     *&#64;&#64;     output tensor data from the Response Cache to the response object.
     *&#64;&#64;     On cache hits, triton does not need to go to the model/backend
     *&#64;&#64;     for the output tensor data, so the "compute_input", "compute_infer",
     *&#64;&#64;     and "compute_output" fields are not updated. Assuming the response
     *&#64;&#64;     cache is enabled for a given model, a cache hit occurs for a
     *&#64;&#64;     request to that model when the request metadata (model name,
     *&#64;&#64;     model version, model inputs) hashes to an existing entry in the
     *&#64;&#64;     cache. On a cache miss, the request hash and response output tensor
     *&#64;&#64;     data is added to the cache. See response cache docs for more info:
     *&#64;&#64;
     * https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration cache_hit = 7;</code>
     */
    protected $cache_hit = null;
    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration cache_miss
     *&#64;&#64;
     *&#64;&#64;     The count of response cache misses and cumulative duration to lookup
     *&#64;&#64;     and insert output tensor data from the computed response to the
     * cache.
     *&#64;&#64;     For example, this duration should include the time to copy
     *&#64;&#64;     output tensor data from the response object to the Response Cache.
     *&#64;&#64;     Assuming the response cache is enabled for a given model, a cache
     *&#64;&#64;     miss occurs for a request to that model when the request metadata
     *&#64;&#64;     does NOT hash to an existing entry in the cache. See the response
     *&#64;&#64;     cache docs for more info:
     *&#64;&#64;
     * https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration cache_miss = 8;</code>
     */
    protected $cache_miss = null;

    /**
     * Constructor.
     *
     * @param array $data {
     *     Optional. Data for populating the Message object.
     *
     *     @type \Inference\StatisticDuration $success
     *          &#64;&#64;  .. cpp:var:: StatisticDuration success
     *          &#64;&#64;
     *          &#64;&#64;     Cumulative count and duration for successful inference
     *          &#64;&#64;     request. The "success" count and cumulative duration includes
     *          &#64;&#64;     cache hits.
     *          &#64;&#64;
     *     @type \Inference\StatisticDuration $fail
     *          &#64;&#64;  .. cpp:var:: StatisticDuration fail
     *          &#64;&#64;
     *          &#64;&#64;     Cumulative count and duration for failed inference
     *          &#64;&#64;     request.
     *          &#64;&#64;
     *     @type \Inference\StatisticDuration $queue
     *          &#64;&#64;  .. cpp:var:: StatisticDuration queue
     *          &#64;&#64;
     *          &#64;&#64;     The count and cumulative duration that inference requests wait in
     *          &#64;&#64;     scheduling or other queues. The "queue" count and cumulative
     *          &#64;&#64;     duration includes cache hits.
     *          &#64;&#64;
     *     @type \Inference\StatisticDuration $compute_input
     *          &#64;&#64;  .. cpp:var:: StatisticDuration compute_input
     *          &#64;&#64;
     *          &#64;&#64;     The count and cumulative duration to prepare input tensor data as
     *          &#64;&#64;     required by the model framework / backend. For example, this duration
     *          &#64;&#64;     should include the time to copy input tensor data to the GPU.
     *          &#64;&#64;     The "compute_input" count and cumulative duration do not account for
     *          &#64;&#64;     requests that were a cache hit. See the "cache_hit" field for more
     *          &#64;&#64;     info.
     *          &#64;&#64;
     *     @type \Inference\StatisticDuration $compute_infer
     *          &#64;&#64;  .. cpp:var:: StatisticDuration compute_infer
     *          &#64;&#64;
     *          &#64;&#64;     The count and cumulative duration to execute the model.
     *          &#64;&#64;     The "compute_infer" count and cumulative duration do not account for
     *          &#64;&#64;     requests that were a cache hit. See the "cache_hit" field for more
     *          &#64;&#64;     info.
     *          &#64;&#64;
     *     @type \Inference\StatisticDuration $compute_output
     *          &#64;&#64;  .. cpp:var:: StatisticDuration compute_output
     *          &#64;&#64;
     *          &#64;&#64;     The count and cumulative duration to extract output tensor data
     *          &#64;&#64;     produced by the model framework / backend. For example, this duration
     *          &#64;&#64;     should include the time to copy output tensor data from the GPU.
     *          &#64;&#64;     The "compute_output" count and cumulative duration do not account for
     *          &#64;&#64;     requests that were a cache hit. See the "cache_hit" field for more
     *          &#64;&#64;     info.
     *          &#64;&#64;
     *     @type \Inference\StatisticDuration $cache_hit
     *          &#64;&#64;  .. cpp:var:: StatisticDuration cache_hit
     *          &#64;&#64;
     *          &#64;&#64;     The count of response cache hits and cumulative duration to lookup
     *          &#64;&#64;     and extract output tensor data from the Response Cache on a cache
     *          &#64;&#64;     hit. For example, this duration should include the time to copy
     *          &#64;&#64;     output tensor data from the Response Cache to the response object.
     *          &#64;&#64;     On cache hits, triton does not need to go to the model/backend
     *          &#64;&#64;     for the output tensor data, so the "compute_input", "compute_infer",
     *          &#64;&#64;     and "compute_output" fields are not updated. Assuming the response
     *          &#64;&#64;     cache is enabled for a given model, a cache hit occurs for a
     *          &#64;&#64;     request to that model when the request metadata (model name,
     *          &#64;&#64;     model version, model inputs) hashes to an existing entry in the
     *          &#64;&#64;     cache. On a cache miss, the request hash and response output tensor
     *          &#64;&#64;     data is added to the cache. See response cache docs for more info:
     *          &#64;&#64;
     *           https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *          &#64;&#64;
     *     @type \Inference\StatisticDuration $cache_miss
     *          &#64;&#64;  .. cpp:var:: StatisticDuration cache_miss
     *          &#64;&#64;
     *          &#64;&#64;     The count of response cache misses and cumulative duration to lookup
     *          &#64;&#64;     and insert output tensor data from the computed response to the
     *           cache.
     *          &#64;&#64;     For example, this duration should include the time to copy
     *          &#64;&#64;     output tensor data from the response object to the Response Cache.
     *          &#64;&#64;     Assuming the response cache is enabled for a given model, a cache
     *          &#64;&#64;     miss occurs for a request to that model when the request metadata
     *          &#64;&#64;     does NOT hash to an existing entry in the cache. See the response
     *          &#64;&#64;     cache docs for more info:
     *          &#64;&#64;
     *           https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *          &#64;&#64;
     * }
     */
    public function __construct($data = NULL) {
        \GPBMetadata\GrpcService::initOnce();
        parent::__construct($data);
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration success
     *&#64;&#64;
     *&#64;&#64;     Cumulative count and duration for successful inference
     *&#64;&#64;     request. The "success" count and cumulative duration includes
     *&#64;&#64;     cache hits.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration success = 1;</code>
     * @return \Inference\StatisticDuration
     */
    public function getSuccess()
    {
        return $this->success;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration success
     *&#64;&#64;
     *&#64;&#64;     Cumulative count and duration for successful inference
     *&#64;&#64;     request. The "success" count and cumulative duration includes
     *&#64;&#64;     cache hits.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration success = 1;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setSuccess($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->success = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration fail
     *&#64;&#64;
     *&#64;&#64;     Cumulative count and duration for failed inference
     *&#64;&#64;     request.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration fail = 2;</code>
     * @return \Inference\StatisticDuration
     */
    public function getFail()
    {
        return $this->fail;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration fail
     *&#64;&#64;
     *&#64;&#64;     Cumulative count and duration for failed inference
     *&#64;&#64;     request.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration fail = 2;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setFail($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->fail = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration queue
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration that inference requests wait in
     *&#64;&#64;     scheduling or other queues. The "queue" count and cumulative
     *&#64;&#64;     duration includes cache hits.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration queue = 3;</code>
     * @return \Inference\StatisticDuration
     */
    public function getQueue()
    {
        return $this->queue;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration queue
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration that inference requests wait in
     *&#64;&#64;     scheduling or other queues. The "queue" count and cumulative
     *&#64;&#64;     duration includes cache hits.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration queue = 3;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setQueue($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->queue = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_input
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to prepare input tensor data as
     *&#64;&#64;     required by the model framework / backend. For example, this duration
     *&#64;&#64;     should include the time to copy input tensor data to the GPU.
     *&#64;&#64;     The "compute_input" count and cumulative duration do not account for
     *&#64;&#64;     requests that were a cache hit. See the "cache_hit" field for more
     *&#64;&#64;     info.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_input = 4;</code>
     * @return \Inference\StatisticDuration
     */
    public function getComputeInput()
    {
        return $this->compute_input;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_input
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to prepare input tensor data as
     *&#64;&#64;     required by the model framework / backend. For example, this duration
     *&#64;&#64;     should include the time to copy input tensor data to the GPU.
     *&#64;&#64;     The "compute_input" count and cumulative duration do not account for
     *&#64;&#64;     requests that were a cache hit. See the "cache_hit" field for more
     *&#64;&#64;     info.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_input = 4;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setComputeInput($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->compute_input = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_infer
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to execute the model.
     *&#64;&#64;     The "compute_infer" count and cumulative duration do not account for
     *&#64;&#64;     requests that were a cache hit. See the "cache_hit" field for more
     *&#64;&#64;     info.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_infer = 5;</code>
     * @return \Inference\StatisticDuration
     */
    public function getComputeInfer()
    {
        return $this->compute_infer;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_infer
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to execute the model.
     *&#64;&#64;     The "compute_infer" count and cumulative duration do not account for
     *&#64;&#64;     requests that were a cache hit. See the "cache_hit" field for more
     *&#64;&#64;     info.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_infer = 5;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setComputeInfer($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->compute_infer = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_output
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to extract output tensor data
     *&#64;&#64;     produced by the model framework / backend. For example, this duration
     *&#64;&#64;     should include the time to copy output tensor data from the GPU.
     *&#64;&#64;     The "compute_output" count and cumulative duration do not account for
     *&#64;&#64;     requests that were a cache hit. See the "cache_hit" field for more
     *&#64;&#64;     info.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_output = 6;</code>
     * @return \Inference\StatisticDuration
     */
    public function getComputeOutput()
    {
        return $this->compute_output;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_output
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to extract output tensor data
     *&#64;&#64;     produced by the model framework / backend. For example, this duration
     *&#64;&#64;     should include the time to copy output tensor data from the GPU.
     *&#64;&#64;     The "compute_output" count and cumulative duration do not account for
     *&#64;&#64;     requests that were a cache hit. See the "cache_hit" field for more
     *&#64;&#64;     info.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_output = 6;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setComputeOutput($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->compute_output = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration cache_hit
     *&#64;&#64;
     *&#64;&#64;     The count of response cache hits and cumulative duration to lookup
     *&#64;&#64;     and extract output tensor data from the Response Cache on a cache
     *&#64;&#64;     hit. For example, this duration should include the time to copy
     *&#64;&#64;     output tensor data from the Response Cache to the response object.
     *&#64;&#64;     On cache hits, triton does not need to go to the model/backend
     *&#64;&#64;     for the output tensor data, so the "compute_input", "compute_infer",
     *&#64;&#64;     and "compute_output" fields are not updated. Assuming the response
     *&#64;&#64;     cache is enabled for a given model, a cache hit occurs for a
     *&#64;&#64;     request to that model when the request metadata (model name,
     *&#64;&#64;     model version, model inputs) hashes to an existing entry in the
     *&#64;&#64;     cache. On a cache miss, the request hash and response output tensor
     *&#64;&#64;     data is added to the cache. See response cache docs for more info:
     *&#64;&#64;
     * https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration cache_hit = 7;</code>
     * @return \Inference\StatisticDuration
     */
    public function getCacheHit()
    {
        return $this->cache_hit;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration cache_hit
     *&#64;&#64;
     *&#64;&#64;     The count of response cache hits and cumulative duration to lookup
     *&#64;&#64;     and extract output tensor data from the Response Cache on a cache
     *&#64;&#64;     hit. For example, this duration should include the time to copy
     *&#64;&#64;     output tensor data from the Response Cache to the response object.
     *&#64;&#64;     On cache hits, triton does not need to go to the model/backend
     *&#64;&#64;     for the output tensor data, so the "compute_input", "compute_infer",
     *&#64;&#64;     and "compute_output" fields are not updated. Assuming the response
     *&#64;&#64;     cache is enabled for a given model, a cache hit occurs for a
     *&#64;&#64;     request to that model when the request metadata (model name,
     *&#64;&#64;     model version, model inputs) hashes to an existing entry in the
     *&#64;&#64;     cache. On a cache miss, the request hash and response output tensor
     *&#64;&#64;     data is added to the cache. See response cache docs for more info:
     *&#64;&#64;
     * https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration cache_hit = 7;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setCacheHit($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->cache_hit = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration cache_miss
     *&#64;&#64;
     *&#64;&#64;     The count of response cache misses and cumulative duration to lookup
     *&#64;&#64;     and insert output tensor data from the computed response to the
     * cache.
     *&#64;&#64;     For example, this duration should include the time to copy
     *&#64;&#64;     output tensor data from the response object to the Response Cache.
     *&#64;&#64;     Assuming the response cache is enabled for a given model, a cache
     *&#64;&#64;     miss occurs for a request to that model when the request metadata
     *&#64;&#64;     does NOT hash to an existing entry in the cache. See the response
     *&#64;&#64;     cache docs for more info:
     *&#64;&#64;
     * https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration cache_miss = 8;</code>
     * @return \Inference\StatisticDuration
     */
    public function getCacheMiss()
    {
        return $this->cache_miss;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration cache_miss
     *&#64;&#64;
     *&#64;&#64;     The count of response cache misses and cumulative duration to lookup
     *&#64;&#64;     and insert output tensor data from the computed response to the
     * cache.
     *&#64;&#64;     For example, this duration should include the time to copy
     *&#64;&#64;     output tensor data from the response object to the Response Cache.
     *&#64;&#64;     Assuming the response cache is enabled for a given model, a cache
     *&#64;&#64;     miss occurs for a request to that model when the request metadata
     *&#64;&#64;     does NOT hash to an existing entry in the cache. See the response
     *&#64;&#64;     cache docs for more info:
     *&#64;&#64;
     * https://github.com/triton-inference-server/server/blob/main/docs/response_cache.md
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration cache_miss = 8;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setCacheMiss($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->cache_miss = $var;

        return $this;
    }

}

