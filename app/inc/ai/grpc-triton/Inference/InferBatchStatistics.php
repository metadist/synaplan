<?php
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: grpc_service.proto

namespace Inference;

use Google\Protobuf\Internal\GPBType;
use Google\Protobuf\Internal\RepeatedField;
use Google\Protobuf\Internal\GPBUtil;

/**
 *&#64;&#64;
 *&#64;&#64;.. cpp:var:: message InferBatchStatistics
 *&#64;&#64;
 *&#64;&#64;   Inference batch statistics.
 *&#64;&#64;
 *
 * Generated from protobuf message <code>inference.InferBatchStatistics</code>
 */
class InferBatchStatistics extends \Google\Protobuf\Internal\Message
{
    /**
     *&#64;&#64;  .. cpp:var:: uint64 batch_size
     *&#64;&#64;
     *&#64;&#64;     The size of the batch.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>uint64 batch_size = 1;</code>
     */
    protected $batch_size = 0;
    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_input
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to prepare input tensor data as
     *&#64;&#64;     required by the model framework / backend with the given batch size.
     *&#64;&#64;     For example, this duration should include the time to copy input
     *&#64;&#64;     tensor data to the GPU.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_input = 2;</code>
     */
    protected $compute_input = null;
    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_infer
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to execute the model with the given
     *&#64;&#64;     batch size.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_infer = 3;</code>
     */
    protected $compute_infer = null;
    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_output
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to extract output tensor data
     *&#64;&#64;     produced by the model framework / backend with the given batch size.
     *&#64;&#64;     For example, this duration should include the time to copy output
     *&#64;&#64;     tensor data from the GPU.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_output = 4;</code>
     */
    protected $compute_output = null;

    /**
     * Constructor.
     *
     * @param array $data {
     *     Optional. Data for populating the Message object.
     *
     *     @type int|string $batch_size
     *          &#64;&#64;  .. cpp:var:: uint64 batch_size
     *          &#64;&#64;
     *          &#64;&#64;     The size of the batch.
     *          &#64;&#64;
     *     @type \Inference\StatisticDuration $compute_input
     *          &#64;&#64;  .. cpp:var:: StatisticDuration compute_input
     *          &#64;&#64;
     *          &#64;&#64;     The count and cumulative duration to prepare input tensor data as
     *          &#64;&#64;     required by the model framework / backend with the given batch size.
     *          &#64;&#64;     For example, this duration should include the time to copy input
     *          &#64;&#64;     tensor data to the GPU.
     *          &#64;&#64;
     *     @type \Inference\StatisticDuration $compute_infer
     *          &#64;&#64;  .. cpp:var:: StatisticDuration compute_infer
     *          &#64;&#64;
     *          &#64;&#64;     The count and cumulative duration to execute the model with the given
     *          &#64;&#64;     batch size.
     *          &#64;&#64;
     *     @type \Inference\StatisticDuration $compute_output
     *          &#64;&#64;  .. cpp:var:: StatisticDuration compute_output
     *          &#64;&#64;
     *          &#64;&#64;     The count and cumulative duration to extract output tensor data
     *          &#64;&#64;     produced by the model framework / backend with the given batch size.
     *          &#64;&#64;     For example, this duration should include the time to copy output
     *          &#64;&#64;     tensor data from the GPU.
     *          &#64;&#64;
     * }
     */
    public function __construct($data = NULL) {
        \GPBMetadata\GrpcService::initOnce();
        parent::__construct($data);
    }

    /**
     *&#64;&#64;  .. cpp:var:: uint64 batch_size
     *&#64;&#64;
     *&#64;&#64;     The size of the batch.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>uint64 batch_size = 1;</code>
     * @return int|string
     */
    public function getBatchSize()
    {
        return $this->batch_size;
    }

    /**
     *&#64;&#64;  .. cpp:var:: uint64 batch_size
     *&#64;&#64;
     *&#64;&#64;     The size of the batch.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>uint64 batch_size = 1;</code>
     * @param int|string $var
     * @return $this
     */
    public function setBatchSize($var)
    {
        GPBUtil::checkUint64($var);
        $this->batch_size = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_input
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to prepare input tensor data as
     *&#64;&#64;     required by the model framework / backend with the given batch size.
     *&#64;&#64;     For example, this duration should include the time to copy input
     *&#64;&#64;     tensor data to the GPU.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_input = 2;</code>
     * @return \Inference\StatisticDuration
     */
    public function getComputeInput()
    {
        return $this->compute_input;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_input
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to prepare input tensor data as
     *&#64;&#64;     required by the model framework / backend with the given batch size.
     *&#64;&#64;     For example, this duration should include the time to copy input
     *&#64;&#64;     tensor data to the GPU.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_input = 2;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setComputeInput($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->compute_input = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_infer
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to execute the model with the given
     *&#64;&#64;     batch size.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_infer = 3;</code>
     * @return \Inference\StatisticDuration
     */
    public function getComputeInfer()
    {
        return $this->compute_infer;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_infer
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to execute the model with the given
     *&#64;&#64;     batch size.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_infer = 3;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setComputeInfer($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->compute_infer = $var;

        return $this;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_output
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to extract output tensor data
     *&#64;&#64;     produced by the model framework / backend with the given batch size.
     *&#64;&#64;     For example, this duration should include the time to copy output
     *&#64;&#64;     tensor data from the GPU.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_output = 4;</code>
     * @return \Inference\StatisticDuration
     */
    public function getComputeOutput()
    {
        return $this->compute_output;
    }

    /**
     *&#64;&#64;  .. cpp:var:: StatisticDuration compute_output
     *&#64;&#64;
     *&#64;&#64;     The count and cumulative duration to extract output tensor data
     *&#64;&#64;     produced by the model framework / backend with the given batch size.
     *&#64;&#64;     For example, this duration should include the time to copy output
     *&#64;&#64;     tensor data from the GPU.
     *&#64;&#64;
     *
     * Generated from protobuf field <code>.inference.StatisticDuration compute_output = 4;</code>
     * @param \Inference\StatisticDuration $var
     * @return $this
     */
    public function setComputeOutput($var)
    {
        GPBUtil::checkMessage($var, \Inference\StatisticDuration::class);
        $this->compute_output = $var;

        return $this;
    }

}

